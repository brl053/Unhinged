/**
 * Test the Universal System with Live LLM
 * 
 * This script tests the complete Universal System pipeline:
 * Voice Command ‚Üí LLM Processing ‚Üí UI Generation ‚Üí Component Rendering
 */

const axios = require('axios');

// Test LLM connectivity and UI generation
async function testUniversalSystemWithLiveLLM() {
  console.log('üöÄ Testing Universal System with Live LLM...');
  console.log('================================================');
  
  try {
    // Step 1: Test LLM connectivity
    console.log('ü§ñ Testing LLM service...');
    const healthResponse = await axios.get('http://localhost:11434/api/tags');
    const models = healthResponse.data.models;
    console.log(`‚úÖ LLM Service Active: ${models.length} model(s) available`);
    console.log(`   üì¶ Model: ${models[0].name} (${models[0].details.parameter_size})`);
    
    // Step 2: Test UI generation with LLM
    console.log('\nüé® Testing UI generation...');
    const prompt = `Generate a JSON schema for a voice input component with the following requirements:
- Component name: "VoiceInput"
- Props: placeholder (string), variant (string), size (string)
- State: isRecording (boolean), transcription (string), audioLevel (number)
- Actions: onRecordStart, onRecordStop, onSubmit
- Make it optimized for mobile devices

Return only valid JSON.`;

    const llmResponse = await axios.post('http://localhost:11434/api/generate', {
      model: 'openhermes:latest',
      prompt: prompt,
      stream: false,
      options: {
        temperature: 0.3,
        top_p: 0.9,
        max_tokens: 500
      }
    });

    const generatedSchema = llmResponse.data.response;
    console.log('‚úÖ LLM Generated UI Schema:');
    console.log(generatedSchema.substring(0, 200) + '...');
    
    // Step 3: Test voice command processing
    console.log('\nüé§ Testing voice command processing...');
    const voiceCommand = "Create a voice input with a submit button for mobile";
    
    const voicePrompt = `You are a UI generation assistant. Convert this voice command into a structured component definition:
"${voiceCommand}"

Respond with a JSON object containing:
- intent: the detected UI intent
- components: array of component definitions
- confidence: confidence score (0-1)
- adaptations: suggested adaptations for the context

Return only valid JSON.`;

    const voiceResponse = await axios.post('http://localhost:11434/api/generate', {
      model: 'openhermes:latest',
      prompt: voicePrompt,
      stream: false,
      options: {
        temperature: 0.2,
        top_p: 0.8,
        max_tokens: 400
      }
    });

    const voiceResult = voiceResponse.data.response;
    console.log('‚úÖ Voice Command Processed:');
    console.log(`   üéØ Command: "${voiceCommand}"`);
    console.log(`   üß† LLM Response: ${voiceResult.substring(0, 150)}...`);
    
    // Step 4: Test context-aware adaptation
    console.log('\nüîß Testing context-aware adaptation...');
    const contextPrompt = `Given this context:
- Device: Mobile phone
- Environment: Noisy
- Accessibility: Screen reader enabled
- User preference: Voice interaction

How should a VoiceInput component be adapted? Provide specific adaptations in JSON format.`;

    const contextResponse = await axios.post('http://localhost:11434/api/generate', {
      model: 'openhermes:latest',
      prompt: contextPrompt,
      stream: false,
      options: {
        temperature: 0.1,
        top_p: 0.7,
        max_tokens: 300
      }
    });

    const contextAdaptations = contextResponse.data.response;
    console.log('‚úÖ Context Adaptations Generated:');
    console.log(contextAdaptations.substring(0, 200) + '...');
    
    // Step 5: Summary
    console.log('\nüéâ Universal System Test Results:');
    console.log('=====================================');
    console.log('‚úÖ LLM Service: ACTIVE');
    console.log('‚úÖ UI Generation: WORKING');
    console.log('‚úÖ Voice Processing: WORKING');
    console.log('‚úÖ Context Adaptation: WORKING');
    console.log('');
    console.log('üöÄ Your Universal System is ready for:');
    console.log('   üé§ Voice-to-UI generation');
    console.log('   üß† Intelligent component creation');
    console.log('   üé® Context-aware adaptations');
    console.log('   üì± Multi-device optimization');
    console.log('   ‚ôø Accessibility enhancements');
    console.log('');
    console.log('üí° Try these voice commands:');
    console.log('   "Create a voice input for mobile"');
    console.log('   "Add a submit button with confirmation"');
    console.log('   "Make a dashboard for stock data"');
    console.log('   "Show me a form with name and email fields"');
    
  } catch (error) {
    console.error('‚ùå Test failed:', error.message);
    if (error.response) {
      console.error('   Response:', error.response.status, error.response.statusText);
    }
  }
}

// Run the test
testUniversalSystemWithLiveLLM();
