// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v1.181.2
//   protoc               v3.21.12
// source: audio.proto

/* eslint-disable */
import {
  type CallOptions,
  ChannelCredentials,
  Client,
  type ClientOptions,
  ClientReadableStream,
  type ClientUnaryCall,
  ClientWritableStream,
  handleClientStreamingCall,
  handleServerStreamingCall,
  type handleUnaryCall,
  makeGenericClientConstructor,
  Metadata,
  type ServiceError,
  type UntypedServiceImplementation,
} from "@grpc/grpc-js";
import Long from "long";
import _m0 from "protobufjs/minimal";
import {
  Attachment,
  AudioUsage,
  Filter,
  HealthCheckRequest,
  HealthCheckResponse,
  PaginationRequest,
  PaginationResponse,
  ResourceMetadata,
  StandardResponse,
  StreamChunk,
} from "./common";

/** Audio quality levels */
export enum AudioQuality {
  AUDIO_QUALITY_UNSPECIFIED = 0,
  /** AUDIO_QUALITY_LOW - 16kHz, compressed */
  AUDIO_QUALITY_LOW = 1,
  /** AUDIO_QUALITY_STANDARD - 22kHz, balanced */
  AUDIO_QUALITY_STANDARD = 2,
  /** AUDIO_QUALITY_HIGH - 44kHz, high quality */
  AUDIO_QUALITY_HIGH = 3,
  /** AUDIO_QUALITY_PREMIUM - 48kHz, studio quality */
  AUDIO_QUALITY_PREMIUM = 4,
  UNRECOGNIZED = -1,
}

export function audioQualityFromJSON(object: any): AudioQuality {
  switch (object) {
    case 0:
    case "AUDIO_QUALITY_UNSPECIFIED":
      return AudioQuality.AUDIO_QUALITY_UNSPECIFIED;
    case 1:
    case "AUDIO_QUALITY_LOW":
      return AudioQuality.AUDIO_QUALITY_LOW;
    case 2:
    case "AUDIO_QUALITY_STANDARD":
      return AudioQuality.AUDIO_QUALITY_STANDARD;
    case 3:
    case "AUDIO_QUALITY_HIGH":
      return AudioQuality.AUDIO_QUALITY_HIGH;
    case 4:
    case "AUDIO_QUALITY_PREMIUM":
      return AudioQuality.AUDIO_QUALITY_PREMIUM;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AudioQuality.UNRECOGNIZED;
  }
}

export function audioQualityToJSON(object: AudioQuality): string {
  switch (object) {
    case AudioQuality.AUDIO_QUALITY_UNSPECIFIED:
      return "AUDIO_QUALITY_UNSPECIFIED";
    case AudioQuality.AUDIO_QUALITY_LOW:
      return "AUDIO_QUALITY_LOW";
    case AudioQuality.AUDIO_QUALITY_STANDARD:
      return "AUDIO_QUALITY_STANDARD";
    case AudioQuality.AUDIO_QUALITY_HIGH:
      return "AUDIO_QUALITY_HIGH";
    case AudioQuality.AUDIO_QUALITY_PREMIUM:
      return "AUDIO_QUALITY_PREMIUM";
    case AudioQuality.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Audio format specification */
export enum AudioFormat {
  AUDIO_FORMAT_UNSPECIFIED = 0,
  /** AUDIO_FORMAT_WAV - Uncompressed WAV */
  AUDIO_FORMAT_WAV = 1,
  /** AUDIO_FORMAT_MP3 - MP3 compressed */
  AUDIO_FORMAT_MP3 = 2,
  /** AUDIO_FORMAT_OGG - OGG Vorbis */
  AUDIO_FORMAT_OGG = 3,
  /** AUDIO_FORMAT_FLAC - Lossless FLAC */
  AUDIO_FORMAT_FLAC = 4,
  /** AUDIO_FORMAT_PCM - Raw PCM data */
  AUDIO_FORMAT_PCM = 5,
  /** AUDIO_FORMAT_OPUS - Opus codec (low latency) */
  AUDIO_FORMAT_OPUS = 6,
  /** AUDIO_FORMAT_AAC - AAC compressed */
  AUDIO_FORMAT_AAC = 7,
  UNRECOGNIZED = -1,
}

export function audioFormatFromJSON(object: any): AudioFormat {
  switch (object) {
    case 0:
    case "AUDIO_FORMAT_UNSPECIFIED":
      return AudioFormat.AUDIO_FORMAT_UNSPECIFIED;
    case 1:
    case "AUDIO_FORMAT_WAV":
      return AudioFormat.AUDIO_FORMAT_WAV;
    case 2:
    case "AUDIO_FORMAT_MP3":
      return AudioFormat.AUDIO_FORMAT_MP3;
    case 3:
    case "AUDIO_FORMAT_OGG":
      return AudioFormat.AUDIO_FORMAT_OGG;
    case 4:
    case "AUDIO_FORMAT_FLAC":
      return AudioFormat.AUDIO_FORMAT_FLAC;
    case 5:
    case "AUDIO_FORMAT_PCM":
      return AudioFormat.AUDIO_FORMAT_PCM;
    case 6:
    case "AUDIO_FORMAT_OPUS":
      return AudioFormat.AUDIO_FORMAT_OPUS;
    case 7:
    case "AUDIO_FORMAT_AAC":
      return AudioFormat.AUDIO_FORMAT_AAC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AudioFormat.UNRECOGNIZED;
  }
}

export function audioFormatToJSON(object: AudioFormat): string {
  switch (object) {
    case AudioFormat.AUDIO_FORMAT_UNSPECIFIED:
      return "AUDIO_FORMAT_UNSPECIFIED";
    case AudioFormat.AUDIO_FORMAT_WAV:
      return "AUDIO_FORMAT_WAV";
    case AudioFormat.AUDIO_FORMAT_MP3:
      return "AUDIO_FORMAT_MP3";
    case AudioFormat.AUDIO_FORMAT_OGG:
      return "AUDIO_FORMAT_OGG";
    case AudioFormat.AUDIO_FORMAT_FLAC:
      return "AUDIO_FORMAT_FLAC";
    case AudioFormat.AUDIO_FORMAT_PCM:
      return "AUDIO_FORMAT_PCM";
    case AudioFormat.AUDIO_FORMAT_OPUS:
      return "AUDIO_FORMAT_OPUS";
    case AudioFormat.AUDIO_FORMAT_AAC:
      return "AUDIO_FORMAT_AAC";
    case AudioFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Available audio effects */
export enum AudioEffectType {
  AUDIO_EFFECT_TYPE_UNSPECIFIED = 0,
  AUDIO_EFFECT_TYPE_REVERB = 1,
  AUDIO_EFFECT_TYPE_ECHO = 2,
  AUDIO_EFFECT_TYPE_CHORUS = 3,
  AUDIO_EFFECT_TYPE_DISTORTION = 4,
  AUDIO_EFFECT_TYPE_NORMALIZE = 5,
  AUDIO_EFFECT_TYPE_COMPRESSOR = 6,
  UNRECOGNIZED = -1,
}

export function audioEffectTypeFromJSON(object: any): AudioEffectType {
  switch (object) {
    case 0:
    case "AUDIO_EFFECT_TYPE_UNSPECIFIED":
      return AudioEffectType.AUDIO_EFFECT_TYPE_UNSPECIFIED;
    case 1:
    case "AUDIO_EFFECT_TYPE_REVERB":
      return AudioEffectType.AUDIO_EFFECT_TYPE_REVERB;
    case 2:
    case "AUDIO_EFFECT_TYPE_ECHO":
      return AudioEffectType.AUDIO_EFFECT_TYPE_ECHO;
    case 3:
    case "AUDIO_EFFECT_TYPE_CHORUS":
      return AudioEffectType.AUDIO_EFFECT_TYPE_CHORUS;
    case 4:
    case "AUDIO_EFFECT_TYPE_DISTORTION":
      return AudioEffectType.AUDIO_EFFECT_TYPE_DISTORTION;
    case 5:
    case "AUDIO_EFFECT_TYPE_NORMALIZE":
      return AudioEffectType.AUDIO_EFFECT_TYPE_NORMALIZE;
    case 6:
    case "AUDIO_EFFECT_TYPE_COMPRESSOR":
      return AudioEffectType.AUDIO_EFFECT_TYPE_COMPRESSOR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AudioEffectType.UNRECOGNIZED;
  }
}

export function audioEffectTypeToJSON(object: AudioEffectType): string {
  switch (object) {
    case AudioEffectType.AUDIO_EFFECT_TYPE_UNSPECIFIED:
      return "AUDIO_EFFECT_TYPE_UNSPECIFIED";
    case AudioEffectType.AUDIO_EFFECT_TYPE_REVERB:
      return "AUDIO_EFFECT_TYPE_REVERB";
    case AudioEffectType.AUDIO_EFFECT_TYPE_ECHO:
      return "AUDIO_EFFECT_TYPE_ECHO";
    case AudioEffectType.AUDIO_EFFECT_TYPE_CHORUS:
      return "AUDIO_EFFECT_TYPE_CHORUS";
    case AudioEffectType.AUDIO_EFFECT_TYPE_DISTORTION:
      return "AUDIO_EFFECT_TYPE_DISTORTION";
    case AudioEffectType.AUDIO_EFFECT_TYPE_NORMALIZE:
      return "AUDIO_EFFECT_TYPE_NORMALIZE";
    case AudioEffectType.AUDIO_EFFECT_TYPE_COMPRESSOR:
      return "AUDIO_EFFECT_TYPE_COMPRESSOR";
    case AudioEffectType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Voice gender classification */
export enum VoiceGender {
  VOICE_GENDER_UNSPECIFIED = 0,
  VOICE_GENDER_MALE = 1,
  VOICE_GENDER_FEMALE = 2,
  VOICE_GENDER_NEUTRAL = 3,
  VOICE_GENDER_CHILD = 4,
  UNRECOGNIZED = -1,
}

export function voiceGenderFromJSON(object: any): VoiceGender {
  switch (object) {
    case 0:
    case "VOICE_GENDER_UNSPECIFIED":
      return VoiceGender.VOICE_GENDER_UNSPECIFIED;
    case 1:
    case "VOICE_GENDER_MALE":
      return VoiceGender.VOICE_GENDER_MALE;
    case 2:
    case "VOICE_GENDER_FEMALE":
      return VoiceGender.VOICE_GENDER_FEMALE;
    case 3:
    case "VOICE_GENDER_NEUTRAL":
      return VoiceGender.VOICE_GENDER_NEUTRAL;
    case 4:
    case "VOICE_GENDER_CHILD":
      return VoiceGender.VOICE_GENDER_CHILD;
    case -1:
    case "UNRECOGNIZED":
    default:
      return VoiceGender.UNRECOGNIZED;
  }
}

export function voiceGenderToJSON(object: VoiceGender): string {
  switch (object) {
    case VoiceGender.VOICE_GENDER_UNSPECIFIED:
      return "VOICE_GENDER_UNSPECIFIED";
    case VoiceGender.VOICE_GENDER_MALE:
      return "VOICE_GENDER_MALE";
    case VoiceGender.VOICE_GENDER_FEMALE:
      return "VOICE_GENDER_FEMALE";
    case VoiceGender.VOICE_GENDER_NEUTRAL:
      return "VOICE_GENDER_NEUTRAL";
    case VoiceGender.VOICE_GENDER_CHILD:
      return "VOICE_GENDER_CHILD";
    case VoiceGender.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Voice age classification */
export enum VoiceAge {
  VOICE_AGE_UNSPECIFIED = 0,
  /** VOICE_AGE_CHILD - Under 18 */
  VOICE_AGE_CHILD = 1,
  /** VOICE_AGE_YOUNG_ADULT - 18-30 */
  VOICE_AGE_YOUNG_ADULT = 2,
  /** VOICE_AGE_ADULT - 30-50 */
  VOICE_AGE_ADULT = 3,
  /** VOICE_AGE_SENIOR - Over 50 */
  VOICE_AGE_SENIOR = 4,
  UNRECOGNIZED = -1,
}

export function voiceAgeFromJSON(object: any): VoiceAge {
  switch (object) {
    case 0:
    case "VOICE_AGE_UNSPECIFIED":
      return VoiceAge.VOICE_AGE_UNSPECIFIED;
    case 1:
    case "VOICE_AGE_CHILD":
      return VoiceAge.VOICE_AGE_CHILD;
    case 2:
    case "VOICE_AGE_YOUNG_ADULT":
      return VoiceAge.VOICE_AGE_YOUNG_ADULT;
    case 3:
    case "VOICE_AGE_ADULT":
      return VoiceAge.VOICE_AGE_ADULT;
    case 4:
    case "VOICE_AGE_SENIOR":
      return VoiceAge.VOICE_AGE_SENIOR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return VoiceAge.UNRECOGNIZED;
  }
}

export function voiceAgeToJSON(object: VoiceAge): string {
  switch (object) {
    case VoiceAge.VOICE_AGE_UNSPECIFIED:
      return "VOICE_AGE_UNSPECIFIED";
    case VoiceAge.VOICE_AGE_CHILD:
      return "VOICE_AGE_CHILD";
    case VoiceAge.VOICE_AGE_YOUNG_ADULT:
      return "VOICE_AGE_YOUNG_ADULT";
    case VoiceAge.VOICE_AGE_ADULT:
      return "VOICE_AGE_ADULT";
    case VoiceAge.VOICE_AGE_SENIOR:
      return "VOICE_AGE_SENIOR";
    case VoiceAge.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Voice style and personality */
export enum VoiceStyle {
  VOICE_STYLE_UNSPECIFIED = 0,
  /** VOICE_STYLE_CONVERSATIONAL - Natural, casual */
  VOICE_STYLE_CONVERSATIONAL = 1,
  /** VOICE_STYLE_PROFESSIONAL - Business, formal */
  VOICE_STYLE_PROFESSIONAL = 2,
  /** VOICE_STYLE_FRIENDLY - Warm, approachable */
  VOICE_STYLE_FRIENDLY = 3,
  /** VOICE_STYLE_AUTHORITATIVE - Confident, commanding */
  VOICE_STYLE_AUTHORITATIVE = 4,
  /** VOICE_STYLE_CALM - Soothing, relaxed */
  VOICE_STYLE_CALM = 5,
  /** VOICE_STYLE_ENERGETIC - Upbeat, enthusiastic */
  VOICE_STYLE_ENERGETIC = 6,
  /** VOICE_STYLE_DRAMATIC - Expressive, theatrical */
  VOICE_STYLE_DRAMATIC = 7,
  UNRECOGNIZED = -1,
}

export function voiceStyleFromJSON(object: any): VoiceStyle {
  switch (object) {
    case 0:
    case "VOICE_STYLE_UNSPECIFIED":
      return VoiceStyle.VOICE_STYLE_UNSPECIFIED;
    case 1:
    case "VOICE_STYLE_CONVERSATIONAL":
      return VoiceStyle.VOICE_STYLE_CONVERSATIONAL;
    case 2:
    case "VOICE_STYLE_PROFESSIONAL":
      return VoiceStyle.VOICE_STYLE_PROFESSIONAL;
    case 3:
    case "VOICE_STYLE_FRIENDLY":
      return VoiceStyle.VOICE_STYLE_FRIENDLY;
    case 4:
    case "VOICE_STYLE_AUTHORITATIVE":
      return VoiceStyle.VOICE_STYLE_AUTHORITATIVE;
    case 5:
    case "VOICE_STYLE_CALM":
      return VoiceStyle.VOICE_STYLE_CALM;
    case 6:
    case "VOICE_STYLE_ENERGETIC":
      return VoiceStyle.VOICE_STYLE_ENERGETIC;
    case 7:
    case "VOICE_STYLE_DRAMATIC":
      return VoiceStyle.VOICE_STYLE_DRAMATIC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return VoiceStyle.UNRECOGNIZED;
  }
}

export function voiceStyleToJSON(object: VoiceStyle): string {
  switch (object) {
    case VoiceStyle.VOICE_STYLE_UNSPECIFIED:
      return "VOICE_STYLE_UNSPECIFIED";
    case VoiceStyle.VOICE_STYLE_CONVERSATIONAL:
      return "VOICE_STYLE_CONVERSATIONAL";
    case VoiceStyle.VOICE_STYLE_PROFESSIONAL:
      return "VOICE_STYLE_PROFESSIONAL";
    case VoiceStyle.VOICE_STYLE_FRIENDLY:
      return "VOICE_STYLE_FRIENDLY";
    case VoiceStyle.VOICE_STYLE_AUTHORITATIVE:
      return "VOICE_STYLE_AUTHORITATIVE";
    case VoiceStyle.VOICE_STYLE_CALM:
      return "VOICE_STYLE_CALM";
    case VoiceStyle.VOICE_STYLE_ENERGETIC:
      return "VOICE_STYLE_ENERGETIC";
    case VoiceStyle.VOICE_STYLE_DRAMATIC:
      return "VOICE_STYLE_DRAMATIC";
    case VoiceStyle.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum ProcessingType {
  PROCESSING_TYPE_UNSPECIFIED = 0,
  PROCESSING_TYPE_TRANSCRIBE = 1,
  PROCESSING_TYPE_TRANSLATE = 2,
  PROCESSING_TYPE_ENHANCE = 3,
  PROCESSING_TYPE_CONVERT = 4,
  UNRECOGNIZED = -1,
}

export function processingTypeFromJSON(object: any): ProcessingType {
  switch (object) {
    case 0:
    case "PROCESSING_TYPE_UNSPECIFIED":
      return ProcessingType.PROCESSING_TYPE_UNSPECIFIED;
    case 1:
    case "PROCESSING_TYPE_TRANSCRIBE":
      return ProcessingType.PROCESSING_TYPE_TRANSCRIBE;
    case 2:
    case "PROCESSING_TYPE_TRANSLATE":
      return ProcessingType.PROCESSING_TYPE_TRANSLATE;
    case 3:
    case "PROCESSING_TYPE_ENHANCE":
      return ProcessingType.PROCESSING_TYPE_ENHANCE;
    case 4:
    case "PROCESSING_TYPE_CONVERT":
      return ProcessingType.PROCESSING_TYPE_CONVERT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ProcessingType.UNRECOGNIZED;
  }
}

export function processingTypeToJSON(object: ProcessingType): string {
  switch (object) {
    case ProcessingType.PROCESSING_TYPE_UNSPECIFIED:
      return "PROCESSING_TYPE_UNSPECIFIED";
    case ProcessingType.PROCESSING_TYPE_TRANSCRIBE:
      return "PROCESSING_TYPE_TRANSCRIBE";
    case ProcessingType.PROCESSING_TYPE_TRANSLATE:
      return "PROCESSING_TYPE_TRANSLATE";
    case ProcessingType.PROCESSING_TYPE_ENHANCE:
      return "PROCESSING_TYPE_ENHANCE";
    case ProcessingType.PROCESSING_TYPE_CONVERT:
      return "PROCESSING_TYPE_CONVERT";
    case ProcessingType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum AnalysisType {
  ANALYSIS_TYPE_UNSPECIFIED = 0,
  ANALYSIS_TYPE_SPEECH_DETECTION = 1,
  ANALYSIS_TYPE_LANGUAGE_DETECTION = 2,
  ANALYSIS_TYPE_SPEAKER_IDENTIFICATION = 3,
  ANALYSIS_TYPE_EMOTION_DETECTION = 4,
  ANALYSIS_TYPE_QUALITY_ASSESSMENT = 5,
  UNRECOGNIZED = -1,
}

export function analysisTypeFromJSON(object: any): AnalysisType {
  switch (object) {
    case 0:
    case "ANALYSIS_TYPE_UNSPECIFIED":
      return AnalysisType.ANALYSIS_TYPE_UNSPECIFIED;
    case 1:
    case "ANALYSIS_TYPE_SPEECH_DETECTION":
      return AnalysisType.ANALYSIS_TYPE_SPEECH_DETECTION;
    case 2:
    case "ANALYSIS_TYPE_LANGUAGE_DETECTION":
      return AnalysisType.ANALYSIS_TYPE_LANGUAGE_DETECTION;
    case 3:
    case "ANALYSIS_TYPE_SPEAKER_IDENTIFICATION":
      return AnalysisType.ANALYSIS_TYPE_SPEAKER_IDENTIFICATION;
    case 4:
    case "ANALYSIS_TYPE_EMOTION_DETECTION":
      return AnalysisType.ANALYSIS_TYPE_EMOTION_DETECTION;
    case 5:
    case "ANALYSIS_TYPE_QUALITY_ASSESSMENT":
      return AnalysisType.ANALYSIS_TYPE_QUALITY_ASSESSMENT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AnalysisType.UNRECOGNIZED;
  }
}

export function analysisTypeToJSON(object: AnalysisType): string {
  switch (object) {
    case AnalysisType.ANALYSIS_TYPE_UNSPECIFIED:
      return "ANALYSIS_TYPE_UNSPECIFIED";
    case AnalysisType.ANALYSIS_TYPE_SPEECH_DETECTION:
      return "ANALYSIS_TYPE_SPEECH_DETECTION";
    case AnalysisType.ANALYSIS_TYPE_LANGUAGE_DETECTION:
      return "ANALYSIS_TYPE_LANGUAGE_DETECTION";
    case AnalysisType.ANALYSIS_TYPE_SPEAKER_IDENTIFICATION:
      return "ANALYSIS_TYPE_SPEAKER_IDENTIFICATION";
    case AnalysisType.ANALYSIS_TYPE_EMOTION_DETECTION:
      return "ANALYSIS_TYPE_EMOTION_DETECTION";
    case AnalysisType.ANALYSIS_TYPE_QUALITY_ASSESSMENT:
      return "ANALYSIS_TYPE_QUALITY_ASSESSMENT";
    case AnalysisType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Text-to-Speech request */
export interface TTSRequest {
  text: string;
  voiceId: string;
  options?:
    | AudioOptions
    | undefined;
  /** Output configuration */
  outputFormat: AudioFormat;
  sampleRate: number;
  channels: number;
  /** Processing options */
  enableSsml: boolean;
  /** Audio effects to apply */
  effects: AudioEffect[];
}

/** Speech-to-Text response */
export interface STTResponse {
  /** ← DRY! */
  response?: StandardResponse | undefined;
  transcript: string;
  confidence: number;
  segments: TranscriptSegment[];
  /** ← DRY! (duration, bytes, etc.) */
  usage?: AudioUsage | undefined;
  metadata?: STTMetadata | undefined;
}

/** Audio processing options */
export interface AudioOptions {
  /** 0.25 to 4.0 (playback speed) */
  speed: number;
  /** -20 to 20 semitones */
  pitch: number;
  /** 0.0 to 2.0 (volume multiplier) */
  volume: number;
  /** Quality settings */
  quality: AudioQuality;
  enableNoiseReduction: boolean;
  enableEchoCancellation: boolean;
}

/** Audio effects that can be applied */
export interface AudioEffect {
  type: AudioEffectType;
  /** 0.0 to 1.0 */
  intensity: number;
  parameters: { [key: string]: string };
}

export interface AudioEffect_ParametersEntry {
  key: string;
  value: string;
}

/** Transcript segment with timing information */
export interface TranscriptSegment {
  text: string;
  /** Seconds from start */
  startTime: number;
  /** Seconds from start */
  endTime: number;
  /** 0.0 to 1.0 */
  confidence: number;
  /** Word-level timing (optional) */
  words: WordTiming[];
  /** Speaker identification (if available) */
  speakerId: string;
}

/** Word-level timing information */
export interface WordTiming {
  word: string;
  startTime: number;
  endTime: number;
  confidence: number;
}

/** STT processing metadata */
export interface STTMetadata {
  model: string;
  /** Detected or specified language */
  language: string;
  processingTimeMs: number;
  /** Audio analysis */
  signalToNoiseRatio: number;
  /** Words per minute */
  speechRateWpm: number;
  detectedLanguages: string[];
  /** Quality metrics */
  hasBackgroundNoise: boolean;
  hasMultipleSpeakers: boolean;
  detectedQuality: AudioQuality;
}

/** Voice definition for TTS */
export interface Voice {
  /** ← DRY! (id, timestamps, etc.) */
  metadata?: ResourceMetadata | undefined;
  name: string;
  displayName: string;
  description: string;
  language: string;
  /** ISO 639-1 code */
  languageCode: string;
  gender: VoiceGender;
  age: VoiceAge;
  style: VoiceStyle;
  /** Technical specifications */
  supportedFormats: AudioFormat[];
  supportedSampleRates: number[];
  /** Availability and pricing */
  isAvailable: boolean;
  isPremium: boolean;
  /** USD per character */
  costPerCharacter: number;
  /** Preview */
  previewUrl: string;
  previewText: string;
}

/**
 * TTS audio chunk payload
 * Used with common.v1.StreamChunk.data field for binary audio
 */
export interface TTSChunkPayload {
  ttsId: string;
  audioMetadata?: AudioMetadata | undefined;
  chunkIndex: number;
  /** 0.0 to 100.0 */
  progressPercent: number;
}

/**
 * STT audio input payload
 * Used with common.v1.StreamChunk.data field for binary audio input
 */
export interface STTChunkPayload {
  sttId: string;
  audioMetadata?: AudioMetadata | undefined;
  isFinalChunk: boolean;
}

/** Audio metadata for streaming */
export interface AudioMetadata {
  format: AudioFormat;
  sampleRate: number;
  channels: number;
  bitDepth: number;
  durationSeconds: number;
  totalBytes: string;
}

export interface ProcessAudioRequest {
  /** ← DRY! (universal attachment) */
  audioFile?: Attachment | undefined;
  processingType: ProcessingType;
  options?: AudioOptions | undefined;
}

export interface ProcessAudioResponse {
  /** ← DRY! */
  response?:
    | StandardResponse
    | undefined;
  /** For transcription */
  transcript?:
    | string
    | undefined;
  /** For translation */
  translation?:
    | string
    | undefined;
  /** ← DRY! For enhancement */
  enhancedAudio?:
    | Attachment
    | undefined;
  /** ← DRY! For conversion */
  convertedAudio?:
    | Attachment
    | undefined;
  /** ← DRY! */
  usage?: AudioUsage | undefined;
}

export interface ListVoicesRequest {
  language: string;
  gender: VoiceGender;
  style: VoiceStyle;
  premiumOnly: boolean;
  /** ← DRY! */
  pagination?:
    | PaginationRequest
    | undefined;
  /** ← DRY! */
  filters: Filter[];
}

export interface ListVoicesResponse {
  /** ← DRY! */
  response?: StandardResponse | undefined;
  voices: Voice[];
  /** ← DRY! */
  pagination?: PaginationResponse | undefined;
}

export interface GetVoiceRequest {
  voiceId: string;
  includePreview: boolean;
}

export interface GetVoiceResponse {
  /** ← DRY! */
  response?: StandardResponse | undefined;
  voice?: Voice | undefined;
}

export interface CreateCustomVoiceRequest {
  name: string;
  description: string;
  /** ← DRY! */
  trainingSamples: Attachment[];
  targetGender: VoiceGender;
  targetStyle: VoiceStyle;
}

export interface CreateCustomVoiceResponse {
  /** ← DRY! */
  response?: StandardResponse | undefined;
  voice?:
    | Voice
    | undefined;
  /** For tracking training progress */
  trainingJobId: string;
}

export interface ConvertAudioRequest {
  /** ← DRY! */
  inputAudio?: Attachment | undefined;
  targetFormat: AudioFormat;
  targetSampleRate: number;
  options?: AudioOptions | undefined;
}

export interface ConvertAudioResponse {
  /** ← DRY! */
  response?:
    | StandardResponse
    | undefined;
  /** ← DRY! */
  convertedAudio?:
    | Attachment
    | undefined;
  /** ← DRY! */
  usage?: AudioUsage | undefined;
}

export interface AnalyzeAudioRequest {
  /** ← DRY! */
  audioFile?: Attachment | undefined;
  analysisTypes: AnalysisType[];
}

export interface AnalyzeAudioResponse {
  /** ← DRY! */
  response?: StandardResponse | undefined;
  analysis?:
    | AudioAnalysis
    | undefined;
  /** ← DRY! */
  usage?: AudioUsage | undefined;
}

export interface AudioAnalysis {
  /** Speech detection */
  containsSpeech: boolean;
  speechPercentage: number;
  speechSegments: SpeechSegment[];
  /** Language detection */
  detectedLanguages: LanguageDetection[];
  /** Speaker identification */
  speakerCount: number;
  speakerSegments: SpeakerSegment[];
  /** Emotion detection */
  emotionSegments: EmotionSegment[];
  /** Quality assessment */
  qualityMetrics?: AudioQualityMetrics | undefined;
}

export interface SpeechSegment {
  startTime: number;
  endTime: number;
  confidence: number;
}

export interface LanguageDetection {
  language: string;
  languageCode: string;
  confidence: number;
}

export interface SpeakerSegment {
  speakerId: string;
  startTime: number;
  endTime: number;
  confidence: number;
}

export interface EmotionSegment {
  /** "happy", "sad", "angry", "neutral", etc. */
  emotion: string;
  startTime: number;
  endTime: number;
  confidence: number;
  /** 0.0 to 1.0 */
  intensity: number;
}

export interface AudioQualityMetrics {
  signalToNoiseRatio: number;
  dynamicRange: number;
  hasClipping: boolean;
  hasBackgroundNoise: boolean;
  /** 0.0 to 1.0 */
  overallQualityScore: number;
}

function createBaseTTSRequest(): TTSRequest {
  return {
    text: "",
    voiceId: "",
    options: undefined,
    outputFormat: 0,
    sampleRate: 0,
    channels: 0,
    enableSsml: false,
    effects: [],
  };
}

export const TTSRequest = {
  encode(message: TTSRequest, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.text !== "") {
      writer.uint32(10).string(message.text);
    }
    if (message.voiceId !== "") {
      writer.uint32(18).string(message.voiceId);
    }
    if (message.options !== undefined) {
      AudioOptions.encode(message.options, writer.uint32(26).fork()).ldelim();
    }
    if (message.outputFormat !== 0) {
      writer.uint32(32).int32(message.outputFormat);
    }
    if (message.sampleRate !== 0) {
      writer.uint32(40).int32(message.sampleRate);
    }
    if (message.channels !== 0) {
      writer.uint32(48).int32(message.channels);
    }
    if (message.enableSsml !== false) {
      writer.uint32(56).bool(message.enableSsml);
    }
    for (const v of message.effects) {
      AudioEffect.encode(v!, writer.uint32(66).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): TTSRequest {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTTSRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.voiceId = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.options = AudioOptions.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.outputFormat = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.sampleRate = reader.int32();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.channels = reader.int32();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.enableSsml = reader.bool();
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.effects.push(AudioEffect.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TTSRequest {
    return {
      text: isSet(object.text) ? globalThis.String(object.text) : "",
      voiceId: isSet(object.voiceId) ? globalThis.String(object.voiceId) : "",
      options: isSet(object.options) ? AudioOptions.fromJSON(object.options) : undefined,
      outputFormat: isSet(object.outputFormat) ? audioFormatFromJSON(object.outputFormat) : 0,
      sampleRate: isSet(object.sampleRate) ? globalThis.Number(object.sampleRate) : 0,
      channels: isSet(object.channels) ? globalThis.Number(object.channels) : 0,
      enableSsml: isSet(object.enableSsml) ? globalThis.Boolean(object.enableSsml) : false,
      effects: globalThis.Array.isArray(object?.effects) ? object.effects.map((e: any) => AudioEffect.fromJSON(e)) : [],
    };
  },

  toJSON(message: TTSRequest): unknown {
    const obj: any = {};
    if (message.text !== "") {
      obj.text = message.text;
    }
    if (message.voiceId !== "") {
      obj.voiceId = message.voiceId;
    }
    if (message.options !== undefined) {
      obj.options = AudioOptions.toJSON(message.options);
    }
    if (message.outputFormat !== 0) {
      obj.outputFormat = audioFormatToJSON(message.outputFormat);
    }
    if (message.sampleRate !== 0) {
      obj.sampleRate = Math.round(message.sampleRate);
    }
    if (message.channels !== 0) {
      obj.channels = Math.round(message.channels);
    }
    if (message.enableSsml !== false) {
      obj.enableSsml = message.enableSsml;
    }
    if (message.effects?.length) {
      obj.effects = message.effects.map((e) => AudioEffect.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TTSRequest>, I>>(base?: I): TTSRequest {
    return TTSRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TTSRequest>, I>>(object: I): TTSRequest {
    const message = createBaseTTSRequest();
    message.text = object.text ?? "";
    message.voiceId = object.voiceId ?? "";
    message.options = (object.options !== undefined && object.options !== null)
      ? AudioOptions.fromPartial(object.options)
      : undefined;
    message.outputFormat = object.outputFormat ?? 0;
    message.sampleRate = object.sampleRate ?? 0;
    message.channels = object.channels ?? 0;
    message.enableSsml = object.enableSsml ?? false;
    message.effects = object.effects?.map((e) => AudioEffect.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSTTResponse(): STTResponse {
  return { response: undefined, transcript: "", confidence: 0, segments: [], usage: undefined, metadata: undefined };
}

export const STTResponse = {
  encode(message: STTResponse, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.response !== undefined) {
      StandardResponse.encode(message.response, writer.uint32(10).fork()).ldelim();
    }
    if (message.transcript !== "") {
      writer.uint32(18).string(message.transcript);
    }
    if (message.confidence !== 0) {
      writer.uint32(29).float(message.confidence);
    }
    for (const v of message.segments) {
      TranscriptSegment.encode(v!, writer.uint32(34).fork()).ldelim();
    }
    if (message.usage !== undefined) {
      AudioUsage.encode(message.usage, writer.uint32(42).fork()).ldelim();
    }
    if (message.metadata !== undefined) {
      STTMetadata.encode(message.metadata, writer.uint32(50).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): STTResponse {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSTTResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.response = StandardResponse.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.transcript = reader.string();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.confidence = reader.float();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.segments.push(TranscriptSegment.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.usage = AudioUsage.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.metadata = STTMetadata.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): STTResponse {
    return {
      response: isSet(object.response) ? StandardResponse.fromJSON(object.response) : undefined,
      transcript: isSet(object.transcript) ? globalThis.String(object.transcript) : "",
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      segments: globalThis.Array.isArray(object?.segments)
        ? object.segments.map((e: any) => TranscriptSegment.fromJSON(e))
        : [],
      usage: isSet(object.usage) ? AudioUsage.fromJSON(object.usage) : undefined,
      metadata: isSet(object.metadata) ? STTMetadata.fromJSON(object.metadata) : undefined,
    };
  },

  toJSON(message: STTResponse): unknown {
    const obj: any = {};
    if (message.response !== undefined) {
      obj.response = StandardResponse.toJSON(message.response);
    }
    if (message.transcript !== "") {
      obj.transcript = message.transcript;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.segments?.length) {
      obj.segments = message.segments.map((e) => TranscriptSegment.toJSON(e));
    }
    if (message.usage !== undefined) {
      obj.usage = AudioUsage.toJSON(message.usage);
    }
    if (message.metadata !== undefined) {
      obj.metadata = STTMetadata.toJSON(message.metadata);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<STTResponse>, I>>(base?: I): STTResponse {
    return STTResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<STTResponse>, I>>(object: I): STTResponse {
    const message = createBaseSTTResponse();
    message.response = (object.response !== undefined && object.response !== null)
      ? StandardResponse.fromPartial(object.response)
      : undefined;
    message.transcript = object.transcript ?? "";
    message.confidence = object.confidence ?? 0;
    message.segments = object.segments?.map((e) => TranscriptSegment.fromPartial(e)) || [];
    message.usage = (object.usage !== undefined && object.usage !== null)
      ? AudioUsage.fromPartial(object.usage)
      : undefined;
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? STTMetadata.fromPartial(object.metadata)
      : undefined;
    return message;
  },
};

function createBaseAudioOptions(): AudioOptions {
  return { speed: 0, pitch: 0, volume: 0, quality: 0, enableNoiseReduction: false, enableEchoCancellation: false };
}

export const AudioOptions = {
  encode(message: AudioOptions, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.speed !== 0) {
      writer.uint32(13).float(message.speed);
    }
    if (message.pitch !== 0) {
      writer.uint32(21).float(message.pitch);
    }
    if (message.volume !== 0) {
      writer.uint32(29).float(message.volume);
    }
    if (message.quality !== 0) {
      writer.uint32(32).int32(message.quality);
    }
    if (message.enableNoiseReduction !== false) {
      writer.uint32(40).bool(message.enableNoiseReduction);
    }
    if (message.enableEchoCancellation !== false) {
      writer.uint32(48).bool(message.enableEchoCancellation);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AudioOptions {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAudioOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.speed = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.pitch = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.volume = reader.float();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.quality = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.enableNoiseReduction = reader.bool();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.enableEchoCancellation = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AudioOptions {
    return {
      speed: isSet(object.speed) ? globalThis.Number(object.speed) : 0,
      pitch: isSet(object.pitch) ? globalThis.Number(object.pitch) : 0,
      volume: isSet(object.volume) ? globalThis.Number(object.volume) : 0,
      quality: isSet(object.quality) ? audioQualityFromJSON(object.quality) : 0,
      enableNoiseReduction: isSet(object.enableNoiseReduction)
        ? globalThis.Boolean(object.enableNoiseReduction)
        : false,
      enableEchoCancellation: isSet(object.enableEchoCancellation)
        ? globalThis.Boolean(object.enableEchoCancellation)
        : false,
    };
  },

  toJSON(message: AudioOptions): unknown {
    const obj: any = {};
    if (message.speed !== 0) {
      obj.speed = message.speed;
    }
    if (message.pitch !== 0) {
      obj.pitch = message.pitch;
    }
    if (message.volume !== 0) {
      obj.volume = message.volume;
    }
    if (message.quality !== 0) {
      obj.quality = audioQualityToJSON(message.quality);
    }
    if (message.enableNoiseReduction !== false) {
      obj.enableNoiseReduction = message.enableNoiseReduction;
    }
    if (message.enableEchoCancellation !== false) {
      obj.enableEchoCancellation = message.enableEchoCancellation;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AudioOptions>, I>>(base?: I): AudioOptions {
    return AudioOptions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AudioOptions>, I>>(object: I): AudioOptions {
    const message = createBaseAudioOptions();
    message.speed = object.speed ?? 0;
    message.pitch = object.pitch ?? 0;
    message.volume = object.volume ?? 0;
    message.quality = object.quality ?? 0;
    message.enableNoiseReduction = object.enableNoiseReduction ?? false;
    message.enableEchoCancellation = object.enableEchoCancellation ?? false;
    return message;
  },
};

function createBaseAudioEffect(): AudioEffect {
  return { type: 0, intensity: 0, parameters: {} };
}

export const AudioEffect = {
  encode(message: AudioEffect, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.intensity !== 0) {
      writer.uint32(21).float(message.intensity);
    }
    Object.entries(message.parameters).forEach(([key, value]) => {
      AudioEffect_ParametersEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).ldelim();
    });
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AudioEffect {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAudioEffect();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.intensity = reader.float();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          const entry3 = AudioEffect_ParametersEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.parameters[entry3.key] = entry3.value;
          }
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AudioEffect {
    return {
      type: isSet(object.type) ? audioEffectTypeFromJSON(object.type) : 0,
      intensity: isSet(object.intensity) ? globalThis.Number(object.intensity) : 0,
      parameters: isObject(object.parameters)
        ? Object.entries(object.parameters).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: AudioEffect): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = audioEffectTypeToJSON(message.type);
    }
    if (message.intensity !== 0) {
      obj.intensity = message.intensity;
    }
    if (message.parameters) {
      const entries = Object.entries(message.parameters);
      if (entries.length > 0) {
        obj.parameters = {};
        entries.forEach(([k, v]) => {
          obj.parameters[k] = v;
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AudioEffect>, I>>(base?: I): AudioEffect {
    return AudioEffect.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AudioEffect>, I>>(object: I): AudioEffect {
    const message = createBaseAudioEffect();
    message.type = object.type ?? 0;
    message.intensity = object.intensity ?? 0;
    message.parameters = Object.entries(object.parameters ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseAudioEffect_ParametersEntry(): AudioEffect_ParametersEntry {
  return { key: "", value: "" };
}

export const AudioEffect_ParametersEntry = {
  encode(message: AudioEffect_ParametersEntry, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AudioEffect_ParametersEntry {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAudioEffect_ParametersEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AudioEffect_ParametersEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AudioEffect_ParametersEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AudioEffect_ParametersEntry>, I>>(base?: I): AudioEffect_ParametersEntry {
    return AudioEffect_ParametersEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AudioEffect_ParametersEntry>, I>>(object: I): AudioEffect_ParametersEntry {
    const message = createBaseAudioEffect_ParametersEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTranscriptSegment(): TranscriptSegment {
  return { text: "", startTime: 0, endTime: 0, confidence: 0, words: [], speakerId: "" };
}

export const TranscriptSegment = {
  encode(message: TranscriptSegment, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.text !== "") {
      writer.uint32(10).string(message.text);
    }
    if (message.startTime !== 0) {
      writer.uint32(21).float(message.startTime);
    }
    if (message.endTime !== 0) {
      writer.uint32(29).float(message.endTime);
    }
    if (message.confidence !== 0) {
      writer.uint32(37).float(message.confidence);
    }
    for (const v of message.words) {
      WordTiming.encode(v!, writer.uint32(42).fork()).ldelim();
    }
    if (message.speakerId !== "") {
      writer.uint32(50).string(message.speakerId);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): TranscriptSegment {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTranscriptSegment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.startTime = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.endTime = reader.float();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.confidence = reader.float();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.words.push(WordTiming.decode(reader, reader.uint32()));
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.speakerId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TranscriptSegment {
    return {
      text: isSet(object.text) ? globalThis.String(object.text) : "",
      startTime: isSet(object.startTime) ? globalThis.Number(object.startTime) : 0,
      endTime: isSet(object.endTime) ? globalThis.Number(object.endTime) : 0,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      words: globalThis.Array.isArray(object?.words) ? object.words.map((e: any) => WordTiming.fromJSON(e)) : [],
      speakerId: isSet(object.speakerId) ? globalThis.String(object.speakerId) : "",
    };
  },

  toJSON(message: TranscriptSegment): unknown {
    const obj: any = {};
    if (message.text !== "") {
      obj.text = message.text;
    }
    if (message.startTime !== 0) {
      obj.startTime = message.startTime;
    }
    if (message.endTime !== 0) {
      obj.endTime = message.endTime;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.words?.length) {
      obj.words = message.words.map((e) => WordTiming.toJSON(e));
    }
    if (message.speakerId !== "") {
      obj.speakerId = message.speakerId;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TranscriptSegment>, I>>(base?: I): TranscriptSegment {
    return TranscriptSegment.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TranscriptSegment>, I>>(object: I): TranscriptSegment {
    const message = createBaseTranscriptSegment();
    message.text = object.text ?? "";
    message.startTime = object.startTime ?? 0;
    message.endTime = object.endTime ?? 0;
    message.confidence = object.confidence ?? 0;
    message.words = object.words?.map((e) => WordTiming.fromPartial(e)) || [];
    message.speakerId = object.speakerId ?? "";
    return message;
  },
};

function createBaseWordTiming(): WordTiming {
  return { word: "", startTime: 0, endTime: 0, confidence: 0 };
}

export const WordTiming = {
  encode(message: WordTiming, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.word !== "") {
      writer.uint32(10).string(message.word);
    }
    if (message.startTime !== 0) {
      writer.uint32(21).float(message.startTime);
    }
    if (message.endTime !== 0) {
      writer.uint32(29).float(message.endTime);
    }
    if (message.confidence !== 0) {
      writer.uint32(37).float(message.confidence);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): WordTiming {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWordTiming();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.word = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.startTime = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.endTime = reader.float();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.confidence = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WordTiming {
    return {
      word: isSet(object.word) ? globalThis.String(object.word) : "",
      startTime: isSet(object.startTime) ? globalThis.Number(object.startTime) : 0,
      endTime: isSet(object.endTime) ? globalThis.Number(object.endTime) : 0,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
    };
  },

  toJSON(message: WordTiming): unknown {
    const obj: any = {};
    if (message.word !== "") {
      obj.word = message.word;
    }
    if (message.startTime !== 0) {
      obj.startTime = message.startTime;
    }
    if (message.endTime !== 0) {
      obj.endTime = message.endTime;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<WordTiming>, I>>(base?: I): WordTiming {
    return WordTiming.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<WordTiming>, I>>(object: I): WordTiming {
    const message = createBaseWordTiming();
    message.word = object.word ?? "";
    message.startTime = object.startTime ?? 0;
    message.endTime = object.endTime ?? 0;
    message.confidence = object.confidence ?? 0;
    return message;
  },
};

function createBaseSTTMetadata(): STTMetadata {
  return {
    model: "",
    language: "",
    processingTimeMs: 0,
    signalToNoiseRatio: 0,
    speechRateWpm: 0,
    detectedLanguages: [],
    hasBackgroundNoise: false,
    hasMultipleSpeakers: false,
    detectedQuality: 0,
  };
}

export const STTMetadata = {
  encode(message: STTMetadata, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.model !== "") {
      writer.uint32(10).string(message.model);
    }
    if (message.language !== "") {
      writer.uint32(18).string(message.language);
    }
    if (message.processingTimeMs !== 0) {
      writer.uint32(29).float(message.processingTimeMs);
    }
    if (message.signalToNoiseRatio !== 0) {
      writer.uint32(37).float(message.signalToNoiseRatio);
    }
    if (message.speechRateWpm !== 0) {
      writer.uint32(45).float(message.speechRateWpm);
    }
    for (const v of message.detectedLanguages) {
      writer.uint32(50).string(v!);
    }
    if (message.hasBackgroundNoise !== false) {
      writer.uint32(56).bool(message.hasBackgroundNoise);
    }
    if (message.hasMultipleSpeakers !== false) {
      writer.uint32(64).bool(message.hasMultipleSpeakers);
    }
    if (message.detectedQuality !== 0) {
      writer.uint32(72).int32(message.detectedQuality);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): STTMetadata {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSTTMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.model = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.language = reader.string();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.processingTimeMs = reader.float();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.signalToNoiseRatio = reader.float();
          continue;
        case 5:
          if (tag !== 45) {
            break;
          }

          message.speechRateWpm = reader.float();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.detectedLanguages.push(reader.string());
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.hasBackgroundNoise = reader.bool();
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.hasMultipleSpeakers = reader.bool();
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.detectedQuality = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): STTMetadata {
    return {
      model: isSet(object.model) ? globalThis.String(object.model) : "",
      language: isSet(object.language) ? globalThis.String(object.language) : "",
      processingTimeMs: isSet(object.processingTimeMs) ? globalThis.Number(object.processingTimeMs) : 0,
      signalToNoiseRatio: isSet(object.signalToNoiseRatio) ? globalThis.Number(object.signalToNoiseRatio) : 0,
      speechRateWpm: isSet(object.speechRateWpm) ? globalThis.Number(object.speechRateWpm) : 0,
      detectedLanguages: globalThis.Array.isArray(object?.detectedLanguages)
        ? object.detectedLanguages.map((e: any) => globalThis.String(e))
        : [],
      hasBackgroundNoise: isSet(object.hasBackgroundNoise) ? globalThis.Boolean(object.hasBackgroundNoise) : false,
      hasMultipleSpeakers: isSet(object.hasMultipleSpeakers) ? globalThis.Boolean(object.hasMultipleSpeakers) : false,
      detectedQuality: isSet(object.detectedQuality) ? audioQualityFromJSON(object.detectedQuality) : 0,
    };
  },

  toJSON(message: STTMetadata): unknown {
    const obj: any = {};
    if (message.model !== "") {
      obj.model = message.model;
    }
    if (message.language !== "") {
      obj.language = message.language;
    }
    if (message.processingTimeMs !== 0) {
      obj.processingTimeMs = message.processingTimeMs;
    }
    if (message.signalToNoiseRatio !== 0) {
      obj.signalToNoiseRatio = message.signalToNoiseRatio;
    }
    if (message.speechRateWpm !== 0) {
      obj.speechRateWpm = message.speechRateWpm;
    }
    if (message.detectedLanguages?.length) {
      obj.detectedLanguages = message.detectedLanguages;
    }
    if (message.hasBackgroundNoise !== false) {
      obj.hasBackgroundNoise = message.hasBackgroundNoise;
    }
    if (message.hasMultipleSpeakers !== false) {
      obj.hasMultipleSpeakers = message.hasMultipleSpeakers;
    }
    if (message.detectedQuality !== 0) {
      obj.detectedQuality = audioQualityToJSON(message.detectedQuality);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<STTMetadata>, I>>(base?: I): STTMetadata {
    return STTMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<STTMetadata>, I>>(object: I): STTMetadata {
    const message = createBaseSTTMetadata();
    message.model = object.model ?? "";
    message.language = object.language ?? "";
    message.processingTimeMs = object.processingTimeMs ?? 0;
    message.signalToNoiseRatio = object.signalToNoiseRatio ?? 0;
    message.speechRateWpm = object.speechRateWpm ?? 0;
    message.detectedLanguages = object.detectedLanguages?.map((e) => e) || [];
    message.hasBackgroundNoise = object.hasBackgroundNoise ?? false;
    message.hasMultipleSpeakers = object.hasMultipleSpeakers ?? false;
    message.detectedQuality = object.detectedQuality ?? 0;
    return message;
  },
};

function createBaseVoice(): Voice {
  return {
    metadata: undefined,
    name: "",
    displayName: "",
    description: "",
    language: "",
    languageCode: "",
    gender: 0,
    age: 0,
    style: 0,
    supportedFormats: [],
    supportedSampleRates: [],
    isAvailable: false,
    isPremium: false,
    costPerCharacter: 0,
    previewUrl: "",
    previewText: "",
  };
}

export const Voice = {
  encode(message: Voice, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.metadata !== undefined) {
      ResourceMetadata.encode(message.metadata, writer.uint32(10).fork()).ldelim();
    }
    if (message.name !== "") {
      writer.uint32(18).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(26).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(34).string(message.description);
    }
    if (message.language !== "") {
      writer.uint32(42).string(message.language);
    }
    if (message.languageCode !== "") {
      writer.uint32(50).string(message.languageCode);
    }
    if (message.gender !== 0) {
      writer.uint32(56).int32(message.gender);
    }
    if (message.age !== 0) {
      writer.uint32(64).int32(message.age);
    }
    if (message.style !== 0) {
      writer.uint32(72).int32(message.style);
    }
    writer.uint32(82).fork();
    for (const v of message.supportedFormats) {
      writer.int32(v);
    }
    writer.ldelim();
    writer.uint32(90).fork();
    for (const v of message.supportedSampleRates) {
      writer.int32(v);
    }
    writer.ldelim();
    if (message.isAvailable !== false) {
      writer.uint32(96).bool(message.isAvailable);
    }
    if (message.isPremium !== false) {
      writer.uint32(104).bool(message.isPremium);
    }
    if (message.costPerCharacter !== 0) {
      writer.uint32(117).float(message.costPerCharacter);
    }
    if (message.previewUrl !== "") {
      writer.uint32(122).string(message.previewUrl);
    }
    if (message.previewText !== "") {
      writer.uint32(130).string(message.previewText);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): Voice {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVoice();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.metadata = ResourceMetadata.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.name = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.displayName = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.description = reader.string();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.language = reader.string();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 7:
          if (tag !== 56) {
            break;
          }

          message.gender = reader.int32() as any;
          continue;
        case 8:
          if (tag !== 64) {
            break;
          }

          message.age = reader.int32() as any;
          continue;
        case 9:
          if (tag !== 72) {
            break;
          }

          message.style = reader.int32() as any;
          continue;
        case 10:
          if (tag === 80) {
            message.supportedFormats.push(reader.int32() as any);

            continue;
          }

          if (tag === 82) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.supportedFormats.push(reader.int32() as any);
            }

            continue;
          }

          break;
        case 11:
          if (tag === 88) {
            message.supportedSampleRates.push(reader.int32());

            continue;
          }

          if (tag === 90) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.supportedSampleRates.push(reader.int32());
            }

            continue;
          }

          break;
        case 12:
          if (tag !== 96) {
            break;
          }

          message.isAvailable = reader.bool();
          continue;
        case 13:
          if (tag !== 104) {
            break;
          }

          message.isPremium = reader.bool();
          continue;
        case 14:
          if (tag !== 117) {
            break;
          }

          message.costPerCharacter = reader.float();
          continue;
        case 15:
          if (tag !== 122) {
            break;
          }

          message.previewUrl = reader.string();
          continue;
        case 16:
          if (tag !== 130) {
            break;
          }

          message.previewText = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Voice {
    return {
      metadata: isSet(object.metadata) ? ResourceMetadata.fromJSON(object.metadata) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      language: isSet(object.language) ? globalThis.String(object.language) : "",
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      gender: isSet(object.gender) ? voiceGenderFromJSON(object.gender) : 0,
      age: isSet(object.age) ? voiceAgeFromJSON(object.age) : 0,
      style: isSet(object.style) ? voiceStyleFromJSON(object.style) : 0,
      supportedFormats: globalThis.Array.isArray(object?.supportedFormats)
        ? object.supportedFormats.map((e: any) => audioFormatFromJSON(e))
        : [],
      supportedSampleRates: globalThis.Array.isArray(object?.supportedSampleRates)
        ? object.supportedSampleRates.map((e: any) => globalThis.Number(e))
        : [],
      isAvailable: isSet(object.isAvailable) ? globalThis.Boolean(object.isAvailable) : false,
      isPremium: isSet(object.isPremium) ? globalThis.Boolean(object.isPremium) : false,
      costPerCharacter: isSet(object.costPerCharacter) ? globalThis.Number(object.costPerCharacter) : 0,
      previewUrl: isSet(object.previewUrl) ? globalThis.String(object.previewUrl) : "",
      previewText: isSet(object.previewText) ? globalThis.String(object.previewText) : "",
    };
  },

  toJSON(message: Voice): unknown {
    const obj: any = {};
    if (message.metadata !== undefined) {
      obj.metadata = ResourceMetadata.toJSON(message.metadata);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.language !== "") {
      obj.language = message.language;
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.gender !== 0) {
      obj.gender = voiceGenderToJSON(message.gender);
    }
    if (message.age !== 0) {
      obj.age = voiceAgeToJSON(message.age);
    }
    if (message.style !== 0) {
      obj.style = voiceStyleToJSON(message.style);
    }
    if (message.supportedFormats?.length) {
      obj.supportedFormats = message.supportedFormats.map((e) => audioFormatToJSON(e));
    }
    if (message.supportedSampleRates?.length) {
      obj.supportedSampleRates = message.supportedSampleRates.map((e) => Math.round(e));
    }
    if (message.isAvailable !== false) {
      obj.isAvailable = message.isAvailable;
    }
    if (message.isPremium !== false) {
      obj.isPremium = message.isPremium;
    }
    if (message.costPerCharacter !== 0) {
      obj.costPerCharacter = message.costPerCharacter;
    }
    if (message.previewUrl !== "") {
      obj.previewUrl = message.previewUrl;
    }
    if (message.previewText !== "") {
      obj.previewText = message.previewText;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Voice>, I>>(base?: I): Voice {
    return Voice.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Voice>, I>>(object: I): Voice {
    const message = createBaseVoice();
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? ResourceMetadata.fromPartial(object.metadata)
      : undefined;
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.language = object.language ?? "";
    message.languageCode = object.languageCode ?? "";
    message.gender = object.gender ?? 0;
    message.age = object.age ?? 0;
    message.style = object.style ?? 0;
    message.supportedFormats = object.supportedFormats?.map((e) => e) || [];
    message.supportedSampleRates = object.supportedSampleRates?.map((e) => e) || [];
    message.isAvailable = object.isAvailable ?? false;
    message.isPremium = object.isPremium ?? false;
    message.costPerCharacter = object.costPerCharacter ?? 0;
    message.previewUrl = object.previewUrl ?? "";
    message.previewText = object.previewText ?? "";
    return message;
  },
};

function createBaseTTSChunkPayload(): TTSChunkPayload {
  return { ttsId: "", audioMetadata: undefined, chunkIndex: 0, progressPercent: 0 };
}

export const TTSChunkPayload = {
  encode(message: TTSChunkPayload, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.ttsId !== "") {
      writer.uint32(10).string(message.ttsId);
    }
    if (message.audioMetadata !== undefined) {
      AudioMetadata.encode(message.audioMetadata, writer.uint32(18).fork()).ldelim();
    }
    if (message.chunkIndex !== 0) {
      writer.uint32(24).int32(message.chunkIndex);
    }
    if (message.progressPercent !== 0) {
      writer.uint32(37).float(message.progressPercent);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): TTSChunkPayload {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTTSChunkPayload();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.ttsId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.audioMetadata = AudioMetadata.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.chunkIndex = reader.int32();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.progressPercent = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TTSChunkPayload {
    return {
      ttsId: isSet(object.ttsId) ? globalThis.String(object.ttsId) : "",
      audioMetadata: isSet(object.audioMetadata) ? AudioMetadata.fromJSON(object.audioMetadata) : undefined,
      chunkIndex: isSet(object.chunkIndex) ? globalThis.Number(object.chunkIndex) : 0,
      progressPercent: isSet(object.progressPercent) ? globalThis.Number(object.progressPercent) : 0,
    };
  },

  toJSON(message: TTSChunkPayload): unknown {
    const obj: any = {};
    if (message.ttsId !== "") {
      obj.ttsId = message.ttsId;
    }
    if (message.audioMetadata !== undefined) {
      obj.audioMetadata = AudioMetadata.toJSON(message.audioMetadata);
    }
    if (message.chunkIndex !== 0) {
      obj.chunkIndex = Math.round(message.chunkIndex);
    }
    if (message.progressPercent !== 0) {
      obj.progressPercent = message.progressPercent;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TTSChunkPayload>, I>>(base?: I): TTSChunkPayload {
    return TTSChunkPayload.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TTSChunkPayload>, I>>(object: I): TTSChunkPayload {
    const message = createBaseTTSChunkPayload();
    message.ttsId = object.ttsId ?? "";
    message.audioMetadata = (object.audioMetadata !== undefined && object.audioMetadata !== null)
      ? AudioMetadata.fromPartial(object.audioMetadata)
      : undefined;
    message.chunkIndex = object.chunkIndex ?? 0;
    message.progressPercent = object.progressPercent ?? 0;
    return message;
  },
};

function createBaseSTTChunkPayload(): STTChunkPayload {
  return { sttId: "", audioMetadata: undefined, isFinalChunk: false };
}

export const STTChunkPayload = {
  encode(message: STTChunkPayload, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.sttId !== "") {
      writer.uint32(10).string(message.sttId);
    }
    if (message.audioMetadata !== undefined) {
      AudioMetadata.encode(message.audioMetadata, writer.uint32(18).fork()).ldelim();
    }
    if (message.isFinalChunk !== false) {
      writer.uint32(24).bool(message.isFinalChunk);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): STTChunkPayload {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSTTChunkPayload();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.sttId = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.audioMetadata = AudioMetadata.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.isFinalChunk = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): STTChunkPayload {
    return {
      sttId: isSet(object.sttId) ? globalThis.String(object.sttId) : "",
      audioMetadata: isSet(object.audioMetadata) ? AudioMetadata.fromJSON(object.audioMetadata) : undefined,
      isFinalChunk: isSet(object.isFinalChunk) ? globalThis.Boolean(object.isFinalChunk) : false,
    };
  },

  toJSON(message: STTChunkPayload): unknown {
    const obj: any = {};
    if (message.sttId !== "") {
      obj.sttId = message.sttId;
    }
    if (message.audioMetadata !== undefined) {
      obj.audioMetadata = AudioMetadata.toJSON(message.audioMetadata);
    }
    if (message.isFinalChunk !== false) {
      obj.isFinalChunk = message.isFinalChunk;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<STTChunkPayload>, I>>(base?: I): STTChunkPayload {
    return STTChunkPayload.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<STTChunkPayload>, I>>(object: I): STTChunkPayload {
    const message = createBaseSTTChunkPayload();
    message.sttId = object.sttId ?? "";
    message.audioMetadata = (object.audioMetadata !== undefined && object.audioMetadata !== null)
      ? AudioMetadata.fromPartial(object.audioMetadata)
      : undefined;
    message.isFinalChunk = object.isFinalChunk ?? false;
    return message;
  },
};

function createBaseAudioMetadata(): AudioMetadata {
  return { format: 0, sampleRate: 0, channels: 0, bitDepth: 0, durationSeconds: 0, totalBytes: "0" };
}

export const AudioMetadata = {
  encode(message: AudioMetadata, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.format !== 0) {
      writer.uint32(8).int32(message.format);
    }
    if (message.sampleRate !== 0) {
      writer.uint32(16).int32(message.sampleRate);
    }
    if (message.channels !== 0) {
      writer.uint32(24).int32(message.channels);
    }
    if (message.bitDepth !== 0) {
      writer.uint32(32).int32(message.bitDepth);
    }
    if (message.durationSeconds !== 0) {
      writer.uint32(45).float(message.durationSeconds);
    }
    if (message.totalBytes !== "0") {
      writer.uint32(48).int64(message.totalBytes);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AudioMetadata {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAudioMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.format = reader.int32() as any;
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.sampleRate = reader.int32();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.channels = reader.int32();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.bitDepth = reader.int32();
          continue;
        case 5:
          if (tag !== 45) {
            break;
          }

          message.durationSeconds = reader.float();
          continue;
        case 6:
          if (tag !== 48) {
            break;
          }

          message.totalBytes = longToString(reader.int64() as Long);
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AudioMetadata {
    return {
      format: isSet(object.format) ? audioFormatFromJSON(object.format) : 0,
      sampleRate: isSet(object.sampleRate) ? globalThis.Number(object.sampleRate) : 0,
      channels: isSet(object.channels) ? globalThis.Number(object.channels) : 0,
      bitDepth: isSet(object.bitDepth) ? globalThis.Number(object.bitDepth) : 0,
      durationSeconds: isSet(object.durationSeconds) ? globalThis.Number(object.durationSeconds) : 0,
      totalBytes: isSet(object.totalBytes) ? globalThis.String(object.totalBytes) : "0",
    };
  },

  toJSON(message: AudioMetadata): unknown {
    const obj: any = {};
    if (message.format !== 0) {
      obj.format = audioFormatToJSON(message.format);
    }
    if (message.sampleRate !== 0) {
      obj.sampleRate = Math.round(message.sampleRate);
    }
    if (message.channels !== 0) {
      obj.channels = Math.round(message.channels);
    }
    if (message.bitDepth !== 0) {
      obj.bitDepth = Math.round(message.bitDepth);
    }
    if (message.durationSeconds !== 0) {
      obj.durationSeconds = message.durationSeconds;
    }
    if (message.totalBytes !== "0") {
      obj.totalBytes = message.totalBytes;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AudioMetadata>, I>>(base?: I): AudioMetadata {
    return AudioMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AudioMetadata>, I>>(object: I): AudioMetadata {
    const message = createBaseAudioMetadata();
    message.format = object.format ?? 0;
    message.sampleRate = object.sampleRate ?? 0;
    message.channels = object.channels ?? 0;
    message.bitDepth = object.bitDepth ?? 0;
    message.durationSeconds = object.durationSeconds ?? 0;
    message.totalBytes = object.totalBytes ?? "0";
    return message;
  },
};

function createBaseProcessAudioRequest(): ProcessAudioRequest {
  return { audioFile: undefined, processingType: 0, options: undefined };
}

export const ProcessAudioRequest = {
  encode(message: ProcessAudioRequest, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.audioFile !== undefined) {
      Attachment.encode(message.audioFile, writer.uint32(10).fork()).ldelim();
    }
    if (message.processingType !== 0) {
      writer.uint32(16).int32(message.processingType);
    }
    if (message.options !== undefined) {
      AudioOptions.encode(message.options, writer.uint32(26).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): ProcessAudioRequest {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProcessAudioRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.audioFile = Attachment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.processingType = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.options = AudioOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ProcessAudioRequest {
    return {
      audioFile: isSet(object.audioFile) ? Attachment.fromJSON(object.audioFile) : undefined,
      processingType: isSet(object.processingType) ? processingTypeFromJSON(object.processingType) : 0,
      options: isSet(object.options) ? AudioOptions.fromJSON(object.options) : undefined,
    };
  },

  toJSON(message: ProcessAudioRequest): unknown {
    const obj: any = {};
    if (message.audioFile !== undefined) {
      obj.audioFile = Attachment.toJSON(message.audioFile);
    }
    if (message.processingType !== 0) {
      obj.processingType = processingTypeToJSON(message.processingType);
    }
    if (message.options !== undefined) {
      obj.options = AudioOptions.toJSON(message.options);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ProcessAudioRequest>, I>>(base?: I): ProcessAudioRequest {
    return ProcessAudioRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ProcessAudioRequest>, I>>(object: I): ProcessAudioRequest {
    const message = createBaseProcessAudioRequest();
    message.audioFile = (object.audioFile !== undefined && object.audioFile !== null)
      ? Attachment.fromPartial(object.audioFile)
      : undefined;
    message.processingType = object.processingType ?? 0;
    message.options = (object.options !== undefined && object.options !== null)
      ? AudioOptions.fromPartial(object.options)
      : undefined;
    return message;
  },
};

function createBaseProcessAudioResponse(): ProcessAudioResponse {
  return {
    response: undefined,
    transcript: undefined,
    translation: undefined,
    enhancedAudio: undefined,
    convertedAudio: undefined,
    usage: undefined,
  };
}

export const ProcessAudioResponse = {
  encode(message: ProcessAudioResponse, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.response !== undefined) {
      StandardResponse.encode(message.response, writer.uint32(10).fork()).ldelim();
    }
    if (message.transcript !== undefined) {
      writer.uint32(18).string(message.transcript);
    }
    if (message.translation !== undefined) {
      writer.uint32(26).string(message.translation);
    }
    if (message.enhancedAudio !== undefined) {
      Attachment.encode(message.enhancedAudio, writer.uint32(34).fork()).ldelim();
    }
    if (message.convertedAudio !== undefined) {
      Attachment.encode(message.convertedAudio, writer.uint32(42).fork()).ldelim();
    }
    if (message.usage !== undefined) {
      AudioUsage.encode(message.usage, writer.uint32(50).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): ProcessAudioResponse {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseProcessAudioResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.response = StandardResponse.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.transcript = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.translation = reader.string();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.enhancedAudio = Attachment.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.convertedAudio = Attachment.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.usage = AudioUsage.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ProcessAudioResponse {
    return {
      response: isSet(object.response) ? StandardResponse.fromJSON(object.response) : undefined,
      transcript: isSet(object.transcript) ? globalThis.String(object.transcript) : undefined,
      translation: isSet(object.translation) ? globalThis.String(object.translation) : undefined,
      enhancedAudio: isSet(object.enhancedAudio) ? Attachment.fromJSON(object.enhancedAudio) : undefined,
      convertedAudio: isSet(object.convertedAudio) ? Attachment.fromJSON(object.convertedAudio) : undefined,
      usage: isSet(object.usage) ? AudioUsage.fromJSON(object.usage) : undefined,
    };
  },

  toJSON(message: ProcessAudioResponse): unknown {
    const obj: any = {};
    if (message.response !== undefined) {
      obj.response = StandardResponse.toJSON(message.response);
    }
    if (message.transcript !== undefined) {
      obj.transcript = message.transcript;
    }
    if (message.translation !== undefined) {
      obj.translation = message.translation;
    }
    if (message.enhancedAudio !== undefined) {
      obj.enhancedAudio = Attachment.toJSON(message.enhancedAudio);
    }
    if (message.convertedAudio !== undefined) {
      obj.convertedAudio = Attachment.toJSON(message.convertedAudio);
    }
    if (message.usage !== undefined) {
      obj.usage = AudioUsage.toJSON(message.usage);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ProcessAudioResponse>, I>>(base?: I): ProcessAudioResponse {
    return ProcessAudioResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ProcessAudioResponse>, I>>(object: I): ProcessAudioResponse {
    const message = createBaseProcessAudioResponse();
    message.response = (object.response !== undefined && object.response !== null)
      ? StandardResponse.fromPartial(object.response)
      : undefined;
    message.transcript = object.transcript ?? undefined;
    message.translation = object.translation ?? undefined;
    message.enhancedAudio = (object.enhancedAudio !== undefined && object.enhancedAudio !== null)
      ? Attachment.fromPartial(object.enhancedAudio)
      : undefined;
    message.convertedAudio = (object.convertedAudio !== undefined && object.convertedAudio !== null)
      ? Attachment.fromPartial(object.convertedAudio)
      : undefined;
    message.usage = (object.usage !== undefined && object.usage !== null)
      ? AudioUsage.fromPartial(object.usage)
      : undefined;
    return message;
  },
};

function createBaseListVoicesRequest(): ListVoicesRequest {
  return { language: "", gender: 0, style: 0, premiumOnly: false, pagination: undefined, filters: [] };
}

export const ListVoicesRequest = {
  encode(message: ListVoicesRequest, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.language !== "") {
      writer.uint32(10).string(message.language);
    }
    if (message.gender !== 0) {
      writer.uint32(16).int32(message.gender);
    }
    if (message.style !== 0) {
      writer.uint32(24).int32(message.style);
    }
    if (message.premiumOnly !== false) {
      writer.uint32(32).bool(message.premiumOnly);
    }
    if (message.pagination !== undefined) {
      PaginationRequest.encode(message.pagination, writer.uint32(42).fork()).ldelim();
    }
    for (const v of message.filters) {
      Filter.encode(v!, writer.uint32(50).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): ListVoicesRequest {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListVoicesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.language = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.gender = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.style = reader.int32() as any;
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.premiumOnly = reader.bool();
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.pagination = PaginationRequest.decode(reader, reader.uint32());
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.filters.push(Filter.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListVoicesRequest {
    return {
      language: isSet(object.language) ? globalThis.String(object.language) : "",
      gender: isSet(object.gender) ? voiceGenderFromJSON(object.gender) : 0,
      style: isSet(object.style) ? voiceStyleFromJSON(object.style) : 0,
      premiumOnly: isSet(object.premiumOnly) ? globalThis.Boolean(object.premiumOnly) : false,
      pagination: isSet(object.pagination) ? PaginationRequest.fromJSON(object.pagination) : undefined,
      filters: globalThis.Array.isArray(object?.filters) ? object.filters.map((e: any) => Filter.fromJSON(e)) : [],
    };
  },

  toJSON(message: ListVoicesRequest): unknown {
    const obj: any = {};
    if (message.language !== "") {
      obj.language = message.language;
    }
    if (message.gender !== 0) {
      obj.gender = voiceGenderToJSON(message.gender);
    }
    if (message.style !== 0) {
      obj.style = voiceStyleToJSON(message.style);
    }
    if (message.premiumOnly !== false) {
      obj.premiumOnly = message.premiumOnly;
    }
    if (message.pagination !== undefined) {
      obj.pagination = PaginationRequest.toJSON(message.pagination);
    }
    if (message.filters?.length) {
      obj.filters = message.filters.map((e) => Filter.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ListVoicesRequest>, I>>(base?: I): ListVoicesRequest {
    return ListVoicesRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ListVoicesRequest>, I>>(object: I): ListVoicesRequest {
    const message = createBaseListVoicesRequest();
    message.language = object.language ?? "";
    message.gender = object.gender ?? 0;
    message.style = object.style ?? 0;
    message.premiumOnly = object.premiumOnly ?? false;
    message.pagination = (object.pagination !== undefined && object.pagination !== null)
      ? PaginationRequest.fromPartial(object.pagination)
      : undefined;
    message.filters = object.filters?.map((e) => Filter.fromPartial(e)) || [];
    return message;
  },
};

function createBaseListVoicesResponse(): ListVoicesResponse {
  return { response: undefined, voices: [], pagination: undefined };
}

export const ListVoicesResponse = {
  encode(message: ListVoicesResponse, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.response !== undefined) {
      StandardResponse.encode(message.response, writer.uint32(10).fork()).ldelim();
    }
    for (const v of message.voices) {
      Voice.encode(v!, writer.uint32(18).fork()).ldelim();
    }
    if (message.pagination !== undefined) {
      PaginationResponse.encode(message.pagination, writer.uint32(26).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): ListVoicesResponse {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListVoicesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.response = StandardResponse.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.voices.push(Voice.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.pagination = PaginationResponse.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListVoicesResponse {
    return {
      response: isSet(object.response) ? StandardResponse.fromJSON(object.response) : undefined,
      voices: globalThis.Array.isArray(object?.voices) ? object.voices.map((e: any) => Voice.fromJSON(e)) : [],
      pagination: isSet(object.pagination) ? PaginationResponse.fromJSON(object.pagination) : undefined,
    };
  },

  toJSON(message: ListVoicesResponse): unknown {
    const obj: any = {};
    if (message.response !== undefined) {
      obj.response = StandardResponse.toJSON(message.response);
    }
    if (message.voices?.length) {
      obj.voices = message.voices.map((e) => Voice.toJSON(e));
    }
    if (message.pagination !== undefined) {
      obj.pagination = PaginationResponse.toJSON(message.pagination);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ListVoicesResponse>, I>>(base?: I): ListVoicesResponse {
    return ListVoicesResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ListVoicesResponse>, I>>(object: I): ListVoicesResponse {
    const message = createBaseListVoicesResponse();
    message.response = (object.response !== undefined && object.response !== null)
      ? StandardResponse.fromPartial(object.response)
      : undefined;
    message.voices = object.voices?.map((e) => Voice.fromPartial(e)) || [];
    message.pagination = (object.pagination !== undefined && object.pagination !== null)
      ? PaginationResponse.fromPartial(object.pagination)
      : undefined;
    return message;
  },
};

function createBaseGetVoiceRequest(): GetVoiceRequest {
  return { voiceId: "", includePreview: false };
}

export const GetVoiceRequest = {
  encode(message: GetVoiceRequest, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.voiceId !== "") {
      writer.uint32(10).string(message.voiceId);
    }
    if (message.includePreview !== false) {
      writer.uint32(16).bool(message.includePreview);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): GetVoiceRequest {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetVoiceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.voiceId = reader.string();
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.includePreview = reader.bool();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetVoiceRequest {
    return {
      voiceId: isSet(object.voiceId) ? globalThis.String(object.voiceId) : "",
      includePreview: isSet(object.includePreview) ? globalThis.Boolean(object.includePreview) : false,
    };
  },

  toJSON(message: GetVoiceRequest): unknown {
    const obj: any = {};
    if (message.voiceId !== "") {
      obj.voiceId = message.voiceId;
    }
    if (message.includePreview !== false) {
      obj.includePreview = message.includePreview;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<GetVoiceRequest>, I>>(base?: I): GetVoiceRequest {
    return GetVoiceRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<GetVoiceRequest>, I>>(object: I): GetVoiceRequest {
    const message = createBaseGetVoiceRequest();
    message.voiceId = object.voiceId ?? "";
    message.includePreview = object.includePreview ?? false;
    return message;
  },
};

function createBaseGetVoiceResponse(): GetVoiceResponse {
  return { response: undefined, voice: undefined };
}

export const GetVoiceResponse = {
  encode(message: GetVoiceResponse, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.response !== undefined) {
      StandardResponse.encode(message.response, writer.uint32(10).fork()).ldelim();
    }
    if (message.voice !== undefined) {
      Voice.encode(message.voice, writer.uint32(18).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): GetVoiceResponse {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetVoiceResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.response = StandardResponse.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.voice = Voice.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetVoiceResponse {
    return {
      response: isSet(object.response) ? StandardResponse.fromJSON(object.response) : undefined,
      voice: isSet(object.voice) ? Voice.fromJSON(object.voice) : undefined,
    };
  },

  toJSON(message: GetVoiceResponse): unknown {
    const obj: any = {};
    if (message.response !== undefined) {
      obj.response = StandardResponse.toJSON(message.response);
    }
    if (message.voice !== undefined) {
      obj.voice = Voice.toJSON(message.voice);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<GetVoiceResponse>, I>>(base?: I): GetVoiceResponse {
    return GetVoiceResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<GetVoiceResponse>, I>>(object: I): GetVoiceResponse {
    const message = createBaseGetVoiceResponse();
    message.response = (object.response !== undefined && object.response !== null)
      ? StandardResponse.fromPartial(object.response)
      : undefined;
    message.voice = (object.voice !== undefined && object.voice !== null) ? Voice.fromPartial(object.voice) : undefined;
    return message;
  },
};

function createBaseCreateCustomVoiceRequest(): CreateCustomVoiceRequest {
  return { name: "", description: "", trainingSamples: [], targetGender: 0, targetStyle: 0 };
}

export const CreateCustomVoiceRequest = {
  encode(message: CreateCustomVoiceRequest, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    for (const v of message.trainingSamples) {
      Attachment.encode(v!, writer.uint32(26).fork()).ldelim();
    }
    if (message.targetGender !== 0) {
      writer.uint32(32).int32(message.targetGender);
    }
    if (message.targetStyle !== 0) {
      writer.uint32(40).int32(message.targetStyle);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): CreateCustomVoiceRequest {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateCustomVoiceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.trainingSamples.push(Attachment.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.targetGender = reader.int32() as any;
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.targetStyle = reader.int32() as any;
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateCustomVoiceRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      trainingSamples: globalThis.Array.isArray(object?.trainingSamples)
        ? object.trainingSamples.map((e: any) => Attachment.fromJSON(e))
        : [],
      targetGender: isSet(object.targetGender) ? voiceGenderFromJSON(object.targetGender) : 0,
      targetStyle: isSet(object.targetStyle) ? voiceStyleFromJSON(object.targetStyle) : 0,
    };
  },

  toJSON(message: CreateCustomVoiceRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.trainingSamples?.length) {
      obj.trainingSamples = message.trainingSamples.map((e) => Attachment.toJSON(e));
    }
    if (message.targetGender !== 0) {
      obj.targetGender = voiceGenderToJSON(message.targetGender);
    }
    if (message.targetStyle !== 0) {
      obj.targetStyle = voiceStyleToJSON(message.targetStyle);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CreateCustomVoiceRequest>, I>>(base?: I): CreateCustomVoiceRequest {
    return CreateCustomVoiceRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CreateCustomVoiceRequest>, I>>(object: I): CreateCustomVoiceRequest {
    const message = createBaseCreateCustomVoiceRequest();
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.trainingSamples = object.trainingSamples?.map((e) => Attachment.fromPartial(e)) || [];
    message.targetGender = object.targetGender ?? 0;
    message.targetStyle = object.targetStyle ?? 0;
    return message;
  },
};

function createBaseCreateCustomVoiceResponse(): CreateCustomVoiceResponse {
  return { response: undefined, voice: undefined, trainingJobId: "" };
}

export const CreateCustomVoiceResponse = {
  encode(message: CreateCustomVoiceResponse, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.response !== undefined) {
      StandardResponse.encode(message.response, writer.uint32(10).fork()).ldelim();
    }
    if (message.voice !== undefined) {
      Voice.encode(message.voice, writer.uint32(18).fork()).ldelim();
    }
    if (message.trainingJobId !== "") {
      writer.uint32(26).string(message.trainingJobId);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): CreateCustomVoiceResponse {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateCustomVoiceResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.response = StandardResponse.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.voice = Voice.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.trainingJobId = reader.string();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateCustomVoiceResponse {
    return {
      response: isSet(object.response) ? StandardResponse.fromJSON(object.response) : undefined,
      voice: isSet(object.voice) ? Voice.fromJSON(object.voice) : undefined,
      trainingJobId: isSet(object.trainingJobId) ? globalThis.String(object.trainingJobId) : "",
    };
  },

  toJSON(message: CreateCustomVoiceResponse): unknown {
    const obj: any = {};
    if (message.response !== undefined) {
      obj.response = StandardResponse.toJSON(message.response);
    }
    if (message.voice !== undefined) {
      obj.voice = Voice.toJSON(message.voice);
    }
    if (message.trainingJobId !== "") {
      obj.trainingJobId = message.trainingJobId;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CreateCustomVoiceResponse>, I>>(base?: I): CreateCustomVoiceResponse {
    return CreateCustomVoiceResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CreateCustomVoiceResponse>, I>>(object: I): CreateCustomVoiceResponse {
    const message = createBaseCreateCustomVoiceResponse();
    message.response = (object.response !== undefined && object.response !== null)
      ? StandardResponse.fromPartial(object.response)
      : undefined;
    message.voice = (object.voice !== undefined && object.voice !== null) ? Voice.fromPartial(object.voice) : undefined;
    message.trainingJobId = object.trainingJobId ?? "";
    return message;
  },
};

function createBaseConvertAudioRequest(): ConvertAudioRequest {
  return { inputAudio: undefined, targetFormat: 0, targetSampleRate: 0, options: undefined };
}

export const ConvertAudioRequest = {
  encode(message: ConvertAudioRequest, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.inputAudio !== undefined) {
      Attachment.encode(message.inputAudio, writer.uint32(10).fork()).ldelim();
    }
    if (message.targetFormat !== 0) {
      writer.uint32(16).int32(message.targetFormat);
    }
    if (message.targetSampleRate !== 0) {
      writer.uint32(24).int32(message.targetSampleRate);
    }
    if (message.options !== undefined) {
      AudioOptions.encode(message.options, writer.uint32(34).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): ConvertAudioRequest {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConvertAudioRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.inputAudio = Attachment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 16) {
            break;
          }

          message.targetFormat = reader.int32() as any;
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.targetSampleRate = reader.int32();
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.options = AudioOptions.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConvertAudioRequest {
    return {
      inputAudio: isSet(object.inputAudio) ? Attachment.fromJSON(object.inputAudio) : undefined,
      targetFormat: isSet(object.targetFormat) ? audioFormatFromJSON(object.targetFormat) : 0,
      targetSampleRate: isSet(object.targetSampleRate) ? globalThis.Number(object.targetSampleRate) : 0,
      options: isSet(object.options) ? AudioOptions.fromJSON(object.options) : undefined,
    };
  },

  toJSON(message: ConvertAudioRequest): unknown {
    const obj: any = {};
    if (message.inputAudio !== undefined) {
      obj.inputAudio = Attachment.toJSON(message.inputAudio);
    }
    if (message.targetFormat !== 0) {
      obj.targetFormat = audioFormatToJSON(message.targetFormat);
    }
    if (message.targetSampleRate !== 0) {
      obj.targetSampleRate = Math.round(message.targetSampleRate);
    }
    if (message.options !== undefined) {
      obj.options = AudioOptions.toJSON(message.options);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ConvertAudioRequest>, I>>(base?: I): ConvertAudioRequest {
    return ConvertAudioRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ConvertAudioRequest>, I>>(object: I): ConvertAudioRequest {
    const message = createBaseConvertAudioRequest();
    message.inputAudio = (object.inputAudio !== undefined && object.inputAudio !== null)
      ? Attachment.fromPartial(object.inputAudio)
      : undefined;
    message.targetFormat = object.targetFormat ?? 0;
    message.targetSampleRate = object.targetSampleRate ?? 0;
    message.options = (object.options !== undefined && object.options !== null)
      ? AudioOptions.fromPartial(object.options)
      : undefined;
    return message;
  },
};

function createBaseConvertAudioResponse(): ConvertAudioResponse {
  return { response: undefined, convertedAudio: undefined, usage: undefined };
}

export const ConvertAudioResponse = {
  encode(message: ConvertAudioResponse, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.response !== undefined) {
      StandardResponse.encode(message.response, writer.uint32(10).fork()).ldelim();
    }
    if (message.convertedAudio !== undefined) {
      Attachment.encode(message.convertedAudio, writer.uint32(18).fork()).ldelim();
    }
    if (message.usage !== undefined) {
      AudioUsage.encode(message.usage, writer.uint32(26).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): ConvertAudioResponse {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConvertAudioResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.response = StandardResponse.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.convertedAudio = Attachment.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.usage = AudioUsage.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConvertAudioResponse {
    return {
      response: isSet(object.response) ? StandardResponse.fromJSON(object.response) : undefined,
      convertedAudio: isSet(object.convertedAudio) ? Attachment.fromJSON(object.convertedAudio) : undefined,
      usage: isSet(object.usage) ? AudioUsage.fromJSON(object.usage) : undefined,
    };
  },

  toJSON(message: ConvertAudioResponse): unknown {
    const obj: any = {};
    if (message.response !== undefined) {
      obj.response = StandardResponse.toJSON(message.response);
    }
    if (message.convertedAudio !== undefined) {
      obj.convertedAudio = Attachment.toJSON(message.convertedAudio);
    }
    if (message.usage !== undefined) {
      obj.usage = AudioUsage.toJSON(message.usage);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ConvertAudioResponse>, I>>(base?: I): ConvertAudioResponse {
    return ConvertAudioResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ConvertAudioResponse>, I>>(object: I): ConvertAudioResponse {
    const message = createBaseConvertAudioResponse();
    message.response = (object.response !== undefined && object.response !== null)
      ? StandardResponse.fromPartial(object.response)
      : undefined;
    message.convertedAudio = (object.convertedAudio !== undefined && object.convertedAudio !== null)
      ? Attachment.fromPartial(object.convertedAudio)
      : undefined;
    message.usage = (object.usage !== undefined && object.usage !== null)
      ? AudioUsage.fromPartial(object.usage)
      : undefined;
    return message;
  },
};

function createBaseAnalyzeAudioRequest(): AnalyzeAudioRequest {
  return { audioFile: undefined, analysisTypes: [] };
}

export const AnalyzeAudioRequest = {
  encode(message: AnalyzeAudioRequest, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.audioFile !== undefined) {
      Attachment.encode(message.audioFile, writer.uint32(10).fork()).ldelim();
    }
    writer.uint32(18).fork();
    for (const v of message.analysisTypes) {
      writer.int32(v);
    }
    writer.ldelim();
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AnalyzeAudioRequest {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeAudioRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.audioFile = Attachment.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag === 16) {
            message.analysisTypes.push(reader.int32() as any);

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.analysisTypes.push(reader.int32() as any);
            }

            continue;
          }

          break;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeAudioRequest {
    return {
      audioFile: isSet(object.audioFile) ? Attachment.fromJSON(object.audioFile) : undefined,
      analysisTypes: globalThis.Array.isArray(object?.analysisTypes)
        ? object.analysisTypes.map((e: any) => analysisTypeFromJSON(e))
        : [],
    };
  },

  toJSON(message: AnalyzeAudioRequest): unknown {
    const obj: any = {};
    if (message.audioFile !== undefined) {
      obj.audioFile = Attachment.toJSON(message.audioFile);
    }
    if (message.analysisTypes?.length) {
      obj.analysisTypes = message.analysisTypes.map((e) => analysisTypeToJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AnalyzeAudioRequest>, I>>(base?: I): AnalyzeAudioRequest {
    return AnalyzeAudioRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AnalyzeAudioRequest>, I>>(object: I): AnalyzeAudioRequest {
    const message = createBaseAnalyzeAudioRequest();
    message.audioFile = (object.audioFile !== undefined && object.audioFile !== null)
      ? Attachment.fromPartial(object.audioFile)
      : undefined;
    message.analysisTypes = object.analysisTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseAnalyzeAudioResponse(): AnalyzeAudioResponse {
  return { response: undefined, analysis: undefined, usage: undefined };
}

export const AnalyzeAudioResponse = {
  encode(message: AnalyzeAudioResponse, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.response !== undefined) {
      StandardResponse.encode(message.response, writer.uint32(10).fork()).ldelim();
    }
    if (message.analysis !== undefined) {
      AudioAnalysis.encode(message.analysis, writer.uint32(18).fork()).ldelim();
    }
    if (message.usage !== undefined) {
      AudioUsage.encode(message.usage, writer.uint32(26).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AnalyzeAudioResponse {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnalyzeAudioResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.response = StandardResponse.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.analysis = AudioAnalysis.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.usage = AudioUsage.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnalyzeAudioResponse {
    return {
      response: isSet(object.response) ? StandardResponse.fromJSON(object.response) : undefined,
      analysis: isSet(object.analysis) ? AudioAnalysis.fromJSON(object.analysis) : undefined,
      usage: isSet(object.usage) ? AudioUsage.fromJSON(object.usage) : undefined,
    };
  },

  toJSON(message: AnalyzeAudioResponse): unknown {
    const obj: any = {};
    if (message.response !== undefined) {
      obj.response = StandardResponse.toJSON(message.response);
    }
    if (message.analysis !== undefined) {
      obj.analysis = AudioAnalysis.toJSON(message.analysis);
    }
    if (message.usage !== undefined) {
      obj.usage = AudioUsage.toJSON(message.usage);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AnalyzeAudioResponse>, I>>(base?: I): AnalyzeAudioResponse {
    return AnalyzeAudioResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AnalyzeAudioResponse>, I>>(object: I): AnalyzeAudioResponse {
    const message = createBaseAnalyzeAudioResponse();
    message.response = (object.response !== undefined && object.response !== null)
      ? StandardResponse.fromPartial(object.response)
      : undefined;
    message.analysis = (object.analysis !== undefined && object.analysis !== null)
      ? AudioAnalysis.fromPartial(object.analysis)
      : undefined;
    message.usage = (object.usage !== undefined && object.usage !== null)
      ? AudioUsage.fromPartial(object.usage)
      : undefined;
    return message;
  },
};

function createBaseAudioAnalysis(): AudioAnalysis {
  return {
    containsSpeech: false,
    speechPercentage: 0,
    speechSegments: [],
    detectedLanguages: [],
    speakerCount: 0,
    speakerSegments: [],
    emotionSegments: [],
    qualityMetrics: undefined,
  };
}

export const AudioAnalysis = {
  encode(message: AudioAnalysis, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.containsSpeech !== false) {
      writer.uint32(8).bool(message.containsSpeech);
    }
    if (message.speechPercentage !== 0) {
      writer.uint32(21).float(message.speechPercentage);
    }
    for (const v of message.speechSegments) {
      SpeechSegment.encode(v!, writer.uint32(26).fork()).ldelim();
    }
    for (const v of message.detectedLanguages) {
      LanguageDetection.encode(v!, writer.uint32(34).fork()).ldelim();
    }
    if (message.speakerCount !== 0) {
      writer.uint32(40).int32(message.speakerCount);
    }
    for (const v of message.speakerSegments) {
      SpeakerSegment.encode(v!, writer.uint32(50).fork()).ldelim();
    }
    for (const v of message.emotionSegments) {
      EmotionSegment.encode(v!, writer.uint32(58).fork()).ldelim();
    }
    if (message.qualityMetrics !== undefined) {
      AudioQualityMetrics.encode(message.qualityMetrics, writer.uint32(66).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AudioAnalysis {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAudioAnalysis();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.containsSpeech = reader.bool();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.speechPercentage = reader.float();
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.speechSegments.push(SpeechSegment.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.detectedLanguages.push(LanguageDetection.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.speakerCount = reader.int32();
          continue;
        case 6:
          if (tag !== 50) {
            break;
          }

          message.speakerSegments.push(SpeakerSegment.decode(reader, reader.uint32()));
          continue;
        case 7:
          if (tag !== 58) {
            break;
          }

          message.emotionSegments.push(EmotionSegment.decode(reader, reader.uint32()));
          continue;
        case 8:
          if (tag !== 66) {
            break;
          }

          message.qualityMetrics = AudioQualityMetrics.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AudioAnalysis {
    return {
      containsSpeech: isSet(object.containsSpeech) ? globalThis.Boolean(object.containsSpeech) : false,
      speechPercentage: isSet(object.speechPercentage) ? globalThis.Number(object.speechPercentage) : 0,
      speechSegments: globalThis.Array.isArray(object?.speechSegments)
        ? object.speechSegments.map((e: any) => SpeechSegment.fromJSON(e))
        : [],
      detectedLanguages: globalThis.Array.isArray(object?.detectedLanguages)
        ? object.detectedLanguages.map((e: any) => LanguageDetection.fromJSON(e))
        : [],
      speakerCount: isSet(object.speakerCount) ? globalThis.Number(object.speakerCount) : 0,
      speakerSegments: globalThis.Array.isArray(object?.speakerSegments)
        ? object.speakerSegments.map((e: any) => SpeakerSegment.fromJSON(e))
        : [],
      emotionSegments: globalThis.Array.isArray(object?.emotionSegments)
        ? object.emotionSegments.map((e: any) => EmotionSegment.fromJSON(e))
        : [],
      qualityMetrics: isSet(object.qualityMetrics) ? AudioQualityMetrics.fromJSON(object.qualityMetrics) : undefined,
    };
  },

  toJSON(message: AudioAnalysis): unknown {
    const obj: any = {};
    if (message.containsSpeech !== false) {
      obj.containsSpeech = message.containsSpeech;
    }
    if (message.speechPercentage !== 0) {
      obj.speechPercentage = message.speechPercentage;
    }
    if (message.speechSegments?.length) {
      obj.speechSegments = message.speechSegments.map((e) => SpeechSegment.toJSON(e));
    }
    if (message.detectedLanguages?.length) {
      obj.detectedLanguages = message.detectedLanguages.map((e) => LanguageDetection.toJSON(e));
    }
    if (message.speakerCount !== 0) {
      obj.speakerCount = Math.round(message.speakerCount);
    }
    if (message.speakerSegments?.length) {
      obj.speakerSegments = message.speakerSegments.map((e) => SpeakerSegment.toJSON(e));
    }
    if (message.emotionSegments?.length) {
      obj.emotionSegments = message.emotionSegments.map((e) => EmotionSegment.toJSON(e));
    }
    if (message.qualityMetrics !== undefined) {
      obj.qualityMetrics = AudioQualityMetrics.toJSON(message.qualityMetrics);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AudioAnalysis>, I>>(base?: I): AudioAnalysis {
    return AudioAnalysis.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AudioAnalysis>, I>>(object: I): AudioAnalysis {
    const message = createBaseAudioAnalysis();
    message.containsSpeech = object.containsSpeech ?? false;
    message.speechPercentage = object.speechPercentage ?? 0;
    message.speechSegments = object.speechSegments?.map((e) => SpeechSegment.fromPartial(e)) || [];
    message.detectedLanguages = object.detectedLanguages?.map((e) => LanguageDetection.fromPartial(e)) || [];
    message.speakerCount = object.speakerCount ?? 0;
    message.speakerSegments = object.speakerSegments?.map((e) => SpeakerSegment.fromPartial(e)) || [];
    message.emotionSegments = object.emotionSegments?.map((e) => EmotionSegment.fromPartial(e)) || [];
    message.qualityMetrics = (object.qualityMetrics !== undefined && object.qualityMetrics !== null)
      ? AudioQualityMetrics.fromPartial(object.qualityMetrics)
      : undefined;
    return message;
  },
};

function createBaseSpeechSegment(): SpeechSegment {
  return { startTime: 0, endTime: 0, confidence: 0 };
}

export const SpeechSegment = {
  encode(message: SpeechSegment, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.startTime !== 0) {
      writer.uint32(13).float(message.startTime);
    }
    if (message.endTime !== 0) {
      writer.uint32(21).float(message.endTime);
    }
    if (message.confidence !== 0) {
      writer.uint32(29).float(message.confidence);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): SpeechSegment {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpeechSegment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.startTime = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.endTime = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.confidence = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpeechSegment {
    return {
      startTime: isSet(object.startTime) ? globalThis.Number(object.startTime) : 0,
      endTime: isSet(object.endTime) ? globalThis.Number(object.endTime) : 0,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
    };
  },

  toJSON(message: SpeechSegment): unknown {
    const obj: any = {};
    if (message.startTime !== 0) {
      obj.startTime = message.startTime;
    }
    if (message.endTime !== 0) {
      obj.endTime = message.endTime;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SpeechSegment>, I>>(base?: I): SpeechSegment {
    return SpeechSegment.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SpeechSegment>, I>>(object: I): SpeechSegment {
    const message = createBaseSpeechSegment();
    message.startTime = object.startTime ?? 0;
    message.endTime = object.endTime ?? 0;
    message.confidence = object.confidence ?? 0;
    return message;
  },
};

function createBaseLanguageDetection(): LanguageDetection {
  return { language: "", languageCode: "", confidence: 0 };
}

export const LanguageDetection = {
  encode(message: LanguageDetection, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.language !== "") {
      writer.uint32(10).string(message.language);
    }
    if (message.languageCode !== "") {
      writer.uint32(18).string(message.languageCode);
    }
    if (message.confidence !== 0) {
      writer.uint32(29).float(message.confidence);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): LanguageDetection {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLanguageDetection();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.language = reader.string();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.languageCode = reader.string();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.confidence = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LanguageDetection {
    return {
      language: isSet(object.language) ? globalThis.String(object.language) : "",
      languageCode: isSet(object.languageCode) ? globalThis.String(object.languageCode) : "",
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
    };
  },

  toJSON(message: LanguageDetection): unknown {
    const obj: any = {};
    if (message.language !== "") {
      obj.language = message.language;
    }
    if (message.languageCode !== "") {
      obj.languageCode = message.languageCode;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<LanguageDetection>, I>>(base?: I): LanguageDetection {
    return LanguageDetection.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<LanguageDetection>, I>>(object: I): LanguageDetection {
    const message = createBaseLanguageDetection();
    message.language = object.language ?? "";
    message.languageCode = object.languageCode ?? "";
    message.confidence = object.confidence ?? 0;
    return message;
  },
};

function createBaseSpeakerSegment(): SpeakerSegment {
  return { speakerId: "", startTime: 0, endTime: 0, confidence: 0 };
}

export const SpeakerSegment = {
  encode(message: SpeakerSegment, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.speakerId !== "") {
      writer.uint32(10).string(message.speakerId);
    }
    if (message.startTime !== 0) {
      writer.uint32(21).float(message.startTime);
    }
    if (message.endTime !== 0) {
      writer.uint32(29).float(message.endTime);
    }
    if (message.confidence !== 0) {
      writer.uint32(37).float(message.confidence);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): SpeakerSegment {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpeakerSegment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.speakerId = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.startTime = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.endTime = reader.float();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.confidence = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpeakerSegment {
    return {
      speakerId: isSet(object.speakerId) ? globalThis.String(object.speakerId) : "",
      startTime: isSet(object.startTime) ? globalThis.Number(object.startTime) : 0,
      endTime: isSet(object.endTime) ? globalThis.Number(object.endTime) : 0,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
    };
  },

  toJSON(message: SpeakerSegment): unknown {
    const obj: any = {};
    if (message.speakerId !== "") {
      obj.speakerId = message.speakerId;
    }
    if (message.startTime !== 0) {
      obj.startTime = message.startTime;
    }
    if (message.endTime !== 0) {
      obj.endTime = message.endTime;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SpeakerSegment>, I>>(base?: I): SpeakerSegment {
    return SpeakerSegment.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SpeakerSegment>, I>>(object: I): SpeakerSegment {
    const message = createBaseSpeakerSegment();
    message.speakerId = object.speakerId ?? "";
    message.startTime = object.startTime ?? 0;
    message.endTime = object.endTime ?? 0;
    message.confidence = object.confidence ?? 0;
    return message;
  },
};

function createBaseEmotionSegment(): EmotionSegment {
  return { emotion: "", startTime: 0, endTime: 0, confidence: 0, intensity: 0 };
}

export const EmotionSegment = {
  encode(message: EmotionSegment, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.emotion !== "") {
      writer.uint32(10).string(message.emotion);
    }
    if (message.startTime !== 0) {
      writer.uint32(21).float(message.startTime);
    }
    if (message.endTime !== 0) {
      writer.uint32(29).float(message.endTime);
    }
    if (message.confidence !== 0) {
      writer.uint32(37).float(message.confidence);
    }
    if (message.intensity !== 0) {
      writer.uint32(45).float(message.intensity);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): EmotionSegment {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEmotionSegment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.emotion = reader.string();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.startTime = reader.float();
          continue;
        case 3:
          if (tag !== 29) {
            break;
          }

          message.endTime = reader.float();
          continue;
        case 4:
          if (tag !== 37) {
            break;
          }

          message.confidence = reader.float();
          continue;
        case 5:
          if (tag !== 45) {
            break;
          }

          message.intensity = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EmotionSegment {
    return {
      emotion: isSet(object.emotion) ? globalThis.String(object.emotion) : "",
      startTime: isSet(object.startTime) ? globalThis.Number(object.startTime) : 0,
      endTime: isSet(object.endTime) ? globalThis.Number(object.endTime) : 0,
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      intensity: isSet(object.intensity) ? globalThis.Number(object.intensity) : 0,
    };
  },

  toJSON(message: EmotionSegment): unknown {
    const obj: any = {};
    if (message.emotion !== "") {
      obj.emotion = message.emotion;
    }
    if (message.startTime !== 0) {
      obj.startTime = message.startTime;
    }
    if (message.endTime !== 0) {
      obj.endTime = message.endTime;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.intensity !== 0) {
      obj.intensity = message.intensity;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<EmotionSegment>, I>>(base?: I): EmotionSegment {
    return EmotionSegment.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<EmotionSegment>, I>>(object: I): EmotionSegment {
    const message = createBaseEmotionSegment();
    message.emotion = object.emotion ?? "";
    message.startTime = object.startTime ?? 0;
    message.endTime = object.endTime ?? 0;
    message.confidence = object.confidence ?? 0;
    message.intensity = object.intensity ?? 0;
    return message;
  },
};

function createBaseAudioQualityMetrics(): AudioQualityMetrics {
  return {
    signalToNoiseRatio: 0,
    dynamicRange: 0,
    hasClipping: false,
    hasBackgroundNoise: false,
    overallQualityScore: 0,
  };
}

export const AudioQualityMetrics = {
  encode(message: AudioQualityMetrics, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.signalToNoiseRatio !== 0) {
      writer.uint32(13).float(message.signalToNoiseRatio);
    }
    if (message.dynamicRange !== 0) {
      writer.uint32(21).float(message.dynamicRange);
    }
    if (message.hasClipping !== false) {
      writer.uint32(24).bool(message.hasClipping);
    }
    if (message.hasBackgroundNoise !== false) {
      writer.uint32(32).bool(message.hasBackgroundNoise);
    }
    if (message.overallQualityScore !== 0) {
      writer.uint32(45).float(message.overallQualityScore);
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): AudioQualityMetrics {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAudioQualityMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 13) {
            break;
          }

          message.signalToNoiseRatio = reader.float();
          continue;
        case 2:
          if (tag !== 21) {
            break;
          }

          message.dynamicRange = reader.float();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.hasClipping = reader.bool();
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.hasBackgroundNoise = reader.bool();
          continue;
        case 5:
          if (tag !== 45) {
            break;
          }

          message.overallQualityScore = reader.float();
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AudioQualityMetrics {
    return {
      signalToNoiseRatio: isSet(object.signalToNoiseRatio) ? globalThis.Number(object.signalToNoiseRatio) : 0,
      dynamicRange: isSet(object.dynamicRange) ? globalThis.Number(object.dynamicRange) : 0,
      hasClipping: isSet(object.hasClipping) ? globalThis.Boolean(object.hasClipping) : false,
      hasBackgroundNoise: isSet(object.hasBackgroundNoise) ? globalThis.Boolean(object.hasBackgroundNoise) : false,
      overallQualityScore: isSet(object.overallQualityScore) ? globalThis.Number(object.overallQualityScore) : 0,
    };
  },

  toJSON(message: AudioQualityMetrics): unknown {
    const obj: any = {};
    if (message.signalToNoiseRatio !== 0) {
      obj.signalToNoiseRatio = message.signalToNoiseRatio;
    }
    if (message.dynamicRange !== 0) {
      obj.dynamicRange = message.dynamicRange;
    }
    if (message.hasClipping !== false) {
      obj.hasClipping = message.hasClipping;
    }
    if (message.hasBackgroundNoise !== false) {
      obj.hasBackgroundNoise = message.hasBackgroundNoise;
    }
    if (message.overallQualityScore !== 0) {
      obj.overallQualityScore = message.overallQualityScore;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AudioQualityMetrics>, I>>(base?: I): AudioQualityMetrics {
    return AudioQualityMetrics.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AudioQualityMetrics>, I>>(object: I): AudioQualityMetrics {
    const message = createBaseAudioQualityMetrics();
    message.signalToNoiseRatio = object.signalToNoiseRatio ?? 0;
    message.dynamicRange = object.dynamicRange ?? 0;
    message.hasClipping = object.hasClipping ?? false;
    message.hasBackgroundNoise = object.hasBackgroundNoise ?? false;
    message.overallQualityScore = object.overallQualityScore ?? 0;
    return message;
  },
};

/**
 * Audio processing service for TTS and STT operations
 *
 * Uses common streaming patterns for consistent behavior
 */
export type AudioServiceService = typeof AudioServiceService;
export const AudioServiceService = {
  /** Text-to-Speech (streaming audio output) */
  textToSpeech: {
    path: "/unhinged.audio.v1.AudioService/TextToSpeech",
    requestStream: false,
    responseStream: true,
    requestSerialize: (value: TTSRequest) => Buffer.from(TTSRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => TTSRequest.decode(value),
    responseSerialize: (value: StreamChunk) => Buffer.from(StreamChunk.encode(value).finish()),
    responseDeserialize: (value: Buffer) => StreamChunk.decode(value),
  },
  /** Speech-to-Text (streaming audio input) */
  speechToText: {
    path: "/unhinged.audio.v1.AudioService/SpeechToText",
    requestStream: true,
    responseStream: false,
    requestSerialize: (value: StreamChunk) => Buffer.from(StreamChunk.encode(value).finish()),
    requestDeserialize: (value: Buffer) => StreamChunk.decode(value),
    responseSerialize: (value: STTResponse) => Buffer.from(STTResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => STTResponse.decode(value),
  },
  /** Batch processing */
  processAudioFile: {
    path: "/unhinged.audio.v1.AudioService/ProcessAudioFile",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ProcessAudioRequest) => Buffer.from(ProcessAudioRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ProcessAudioRequest.decode(value),
    responseSerialize: (value: ProcessAudioResponse) => Buffer.from(ProcessAudioResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ProcessAudioResponse.decode(value),
  },
  /** Voice management */
  listVoices: {
    path: "/unhinged.audio.v1.AudioService/ListVoices",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ListVoicesRequest) => Buffer.from(ListVoicesRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ListVoicesRequest.decode(value),
    responseSerialize: (value: ListVoicesResponse) => Buffer.from(ListVoicesResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ListVoicesResponse.decode(value),
  },
  getVoice: {
    path: "/unhinged.audio.v1.AudioService/GetVoice",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetVoiceRequest) => Buffer.from(GetVoiceRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetVoiceRequest.decode(value),
    responseSerialize: (value: GetVoiceResponse) => Buffer.from(GetVoiceResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetVoiceResponse.decode(value),
  },
  createCustomVoice: {
    path: "/unhinged.audio.v1.AudioService/CreateCustomVoice",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: CreateCustomVoiceRequest) => Buffer.from(CreateCustomVoiceRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => CreateCustomVoiceRequest.decode(value),
    responseSerialize: (value: CreateCustomVoiceResponse) =>
      Buffer.from(CreateCustomVoiceResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => CreateCustomVoiceResponse.decode(value),
  },
  /** Audio utilities */
  convertAudioFormat: {
    path: "/unhinged.audio.v1.AudioService/ConvertAudioFormat",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ConvertAudioRequest) => Buffer.from(ConvertAudioRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ConvertAudioRequest.decode(value),
    responseSerialize: (value: ConvertAudioResponse) => Buffer.from(ConvertAudioResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ConvertAudioResponse.decode(value),
  },
  analyzeAudio: {
    path: "/unhinged.audio.v1.AudioService/AnalyzeAudio",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: AnalyzeAudioRequest) => Buffer.from(AnalyzeAudioRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => AnalyzeAudioRequest.decode(value),
    responseSerialize: (value: AnalyzeAudioResponse) => Buffer.from(AnalyzeAudioResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => AnalyzeAudioResponse.decode(value),
  },
  /** Standard health check */
  healthCheck: {
    path: "/unhinged.audio.v1.AudioService/HealthCheck",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: HealthCheckRequest) => Buffer.from(HealthCheckRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => HealthCheckRequest.decode(value),
    responseSerialize: (value: HealthCheckResponse) => Buffer.from(HealthCheckResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => HealthCheckResponse.decode(value),
  },
} as const;

export interface AudioServiceServer extends UntypedServiceImplementation {
  /** Text-to-Speech (streaming audio output) */
  textToSpeech: handleServerStreamingCall<TTSRequest, StreamChunk>;
  /** Speech-to-Text (streaming audio input) */
  speechToText: handleClientStreamingCall<StreamChunk, STTResponse>;
  /** Batch processing */
  processAudioFile: handleUnaryCall<ProcessAudioRequest, ProcessAudioResponse>;
  /** Voice management */
  listVoices: handleUnaryCall<ListVoicesRequest, ListVoicesResponse>;
  getVoice: handleUnaryCall<GetVoiceRequest, GetVoiceResponse>;
  createCustomVoice: handleUnaryCall<CreateCustomVoiceRequest, CreateCustomVoiceResponse>;
  /** Audio utilities */
  convertAudioFormat: handleUnaryCall<ConvertAudioRequest, ConvertAudioResponse>;
  analyzeAudio: handleUnaryCall<AnalyzeAudioRequest, AnalyzeAudioResponse>;
  /** Standard health check */
  healthCheck: handleUnaryCall<HealthCheckRequest, HealthCheckResponse>;
}

export interface AudioServiceClient extends Client {
  /** Text-to-Speech (streaming audio output) */
  textToSpeech(request: TTSRequest, options?: Partial<CallOptions>): ClientReadableStream<StreamChunk>;
  textToSpeech(
    request: TTSRequest,
    metadata?: Metadata,
    options?: Partial<CallOptions>,
  ): ClientReadableStream<StreamChunk>;
  /** Speech-to-Text (streaming audio input) */
  speechToText(
    callback: (error: ServiceError | null, response: STTResponse) => void,
  ): ClientWritableStream<StreamChunk>;
  speechToText(
    metadata: Metadata,
    callback: (error: ServiceError | null, response: STTResponse) => void,
  ): ClientWritableStream<StreamChunk>;
  speechToText(
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: STTResponse) => void,
  ): ClientWritableStream<StreamChunk>;
  speechToText(
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: STTResponse) => void,
  ): ClientWritableStream<StreamChunk>;
  /** Batch processing */
  processAudioFile(
    request: ProcessAudioRequest,
    callback: (error: ServiceError | null, response: ProcessAudioResponse) => void,
  ): ClientUnaryCall;
  processAudioFile(
    request: ProcessAudioRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ProcessAudioResponse) => void,
  ): ClientUnaryCall;
  processAudioFile(
    request: ProcessAudioRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ProcessAudioResponse) => void,
  ): ClientUnaryCall;
  /** Voice management */
  listVoices(
    request: ListVoicesRequest,
    callback: (error: ServiceError | null, response: ListVoicesResponse) => void,
  ): ClientUnaryCall;
  listVoices(
    request: ListVoicesRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ListVoicesResponse) => void,
  ): ClientUnaryCall;
  listVoices(
    request: ListVoicesRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ListVoicesResponse) => void,
  ): ClientUnaryCall;
  getVoice(
    request: GetVoiceRequest,
    callback: (error: ServiceError | null, response: GetVoiceResponse) => void,
  ): ClientUnaryCall;
  getVoice(
    request: GetVoiceRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetVoiceResponse) => void,
  ): ClientUnaryCall;
  getVoice(
    request: GetVoiceRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetVoiceResponse) => void,
  ): ClientUnaryCall;
  createCustomVoice(
    request: CreateCustomVoiceRequest,
    callback: (error: ServiceError | null, response: CreateCustomVoiceResponse) => void,
  ): ClientUnaryCall;
  createCustomVoice(
    request: CreateCustomVoiceRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: CreateCustomVoiceResponse) => void,
  ): ClientUnaryCall;
  createCustomVoice(
    request: CreateCustomVoiceRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: CreateCustomVoiceResponse) => void,
  ): ClientUnaryCall;
  /** Audio utilities */
  convertAudioFormat(
    request: ConvertAudioRequest,
    callback: (error: ServiceError | null, response: ConvertAudioResponse) => void,
  ): ClientUnaryCall;
  convertAudioFormat(
    request: ConvertAudioRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ConvertAudioResponse) => void,
  ): ClientUnaryCall;
  convertAudioFormat(
    request: ConvertAudioRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ConvertAudioResponse) => void,
  ): ClientUnaryCall;
  analyzeAudio(
    request: AnalyzeAudioRequest,
    callback: (error: ServiceError | null, response: AnalyzeAudioResponse) => void,
  ): ClientUnaryCall;
  analyzeAudio(
    request: AnalyzeAudioRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: AnalyzeAudioResponse) => void,
  ): ClientUnaryCall;
  analyzeAudio(
    request: AnalyzeAudioRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: AnalyzeAudioResponse) => void,
  ): ClientUnaryCall;
  /** Standard health check */
  healthCheck(
    request: HealthCheckRequest,
    callback: (error: ServiceError | null, response: HealthCheckResponse) => void,
  ): ClientUnaryCall;
  healthCheck(
    request: HealthCheckRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: HealthCheckResponse) => void,
  ): ClientUnaryCall;
  healthCheck(
    request: HealthCheckRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: HealthCheckResponse) => void,
  ): ClientUnaryCall;
}

export const AudioServiceClient = makeGenericClientConstructor(
  AudioServiceService,
  "unhinged.audio.v1.AudioService",
) as unknown as {
  new (address: string, credentials: ChannelCredentials, options?: Partial<ClientOptions>): AudioServiceClient;
  service: typeof AudioServiceService;
  serviceName: string;
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function longToString(long: Long) {
  return long.toString();
}

if (_m0.util.Long !== Long) {
  _m0.util.Long = Long as any;
  _m0.configure();
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}
