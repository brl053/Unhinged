[
  {
    "file_path": "docker-compose.yml",
    "line_number": 60,
    "element_name": "vision-ai",
    "language": "yaml",
    "llm_type": "config",
    "llm_legend": "Docker service configuration for AI-powered image analysis microservice",
    "llm_key": "Defines Python container with BLIP model, Flask HTTP server, and persistent model storage",
    "llm_map": "Part of microservices architecture, connects backend to vision processing capabilities",
    "llm_axiom": "Vision service must be accessible on port 8001 for backend integration",
    "llm_contract": "Service must respond to health checks within 30 seconds and handle image uploads",
    "llm_token": "vision-models: Docker volume for persistent transformer model cache",
    "llm_context": null,
    "raw_comment": "@llm-type config\n@llm-legend Docker service configuration for AI-powered image analysis microservice\n@llm-key Defines Python container with BLIP model, Flask HTTP server, and persistent model storage\n@llm-map Part of microservices architecture, connects backend to vision processing capabilities\n@llm-axiom Vision service must be accessible on port 8001 for backend integration\n@llm-contract Service must respond to health checks within 30 seconds and handle image uploads\n@llm-token vision-models: Docker volume for persistent transformer model cache",
    "context": "vision-ai:"
  },
  {
    "file_path": "build/llm_integration.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "LLM integration for enhanced build system with context generation and error explanation",
    "llm_key": "Provides AI-powered build assistance, error explanation, and context generation for developer onboarding",
    "llm_map": "LLM integration layer that connects build system with existing documentation system for enhanced developer experience",
    "llm_axiom": "LLM integration must provide helpful, accurate, and contextual assistance without overwhelming developers",
    "llm_contract": "Returns structured LLM responses with build context, error explanations, and optimization suggestions",
    "llm_token": "llm-build-integration: AI-powered assistance for build system operations",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend LLM integration for enhanced build system with context generation and error explanation\n@llm-key Provides AI-powered build assistance, error explanation, and context generation for developer onboarding\n@llm-map LLM integration layer that connects build system with existing documentation system for enhanced developer experience\n@llm-axiom LLM integration must provide helpful, accurate, and contextual assistance without overwhelming developers\n@llm-contract Returns structured LLM responses with build context, error explanations, and optimization suggestions\n@llm-token llm-build-integration: AI-powered assistance for build system operations\n\nLLM Integration for Enhanced Build System\n\nIntegrates the enhanced build system with the existing LLM documentation system\nto provide:\n- Build context generation for AI assistance\n- Error explanation and troubleshooting\n- Optimization suggestions\n- Developer onboarding assistance\n- Build process documentation\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/cli.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Enhanced CLI interface for the Unhinged build system",
    "llm_key": "Provides developer-friendly command-line interface with progress indicators, build status, and LLM integration",
    "llm_map": "CLI layer that wraps the build orchestrator with enhanced user experience and developer tools",
    "llm_axiom": "CLI must provide clear feedback, helpful error messages, and efficient developer workflows",
    "llm_contract": "Returns appropriate exit codes and provides structured output for both humans and scripts",
    "llm_token": "build-cli: Command-line interface for enhanced build system",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Enhanced CLI interface for the Unhinged build system\n@llm-key Provides developer-friendly command-line interface with progress indicators, build status, and LLM integration\n@llm-map CLI layer that wraps the build orchestrator with enhanced user experience and developer tools\n@llm-axiom CLI must provide clear feedback, helpful error messages, and efficient developer workflows\n@llm-contract Returns appropriate exit codes and provides structured output for both humans and scripts\n@llm-token build-cli: Command-line interface for enhanced build system\n\nEnhanced Build System CLI\n\nProvides a developer-friendly command-line interface for the enhanced build system\nwith features like:\n- Real-time progress indicators\n- Build status monitoring\n- LLM-powered error explanation\n- Performance profiling\n- Interactive build selection\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/test_enhanced_system.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Test suite for the enhanced build system",
    "llm_key": "Provides comprehensive testing and validation of the enhanced build system features",
    "llm_map": "Test suite that validates all components of the enhanced build system",
    "llm_axiom": "Tests must be comprehensive, fast, and provide clear feedback on system health",
    "llm_contract": "Returns test results and system validation status",
    "llm_token": "build-test: Comprehensive test suite for enhanced build system",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Test suite for the enhanced build system\n@llm-key Provides comprehensive testing and validation of the enhanced build system features\n@llm-map Test suite that validates all components of the enhanced build system\n@llm-axiom Tests must be comprehensive, fast, and provide clear feedback on system health\n@llm-contract Returns test results and system validation status\n@llm-token build-test: Comprehensive test suite for enhanced build system\n\nEnhanced Build System Test Suite\n\nComprehensive testing and validation for the enhanced build system:\n- Component integration tests\n- Performance validation\n- Cache system tests\n- Multi-language build tests\n- Error handling validation\n- Developer experience tests\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/orchestrator.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Enhanced build orchestrator for Unhinged polyglot monorepo",
    "llm_key": "Provides intelligent dependency tracking, parallel execution, caching, and multi-language build coordination",
    "llm_map": "Central build coordination system that integrates with existing Makefile and Docker Compose workflows",
    "llm_axiom": "Build operations must be deterministic, cacheable, and provide clear feedback to developers",
    "llm_contract": "Returns BuildResult with success status, artifacts, and performance metrics",
    "llm_token": "build-orchestrator: Python service coordinating all build operations across languages",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Enhanced build orchestrator for Unhinged polyglot monorepo\n@llm-key Provides intelligent dependency tracking, parallel execution, caching, and multi-language build coordination\n@llm-map Central build coordination system that integrates with existing Makefile and Docker Compose workflows\n@llm-axiom Build operations must be deterministic, cacheable, and provide clear feedback to developers\n@llm-contract Returns BuildResult with success status, artifacts, and performance metrics\n@llm-token build-orchestrator: Python service coordinating all build operations across languages\n\nEnhanced Build Orchestrator for Unhinged Platform\n\nCoordinates builds across Kotlin, TypeScript, Python, and Protobuf with intelligent\ndependency tracking, parallel execution, and comprehensive caching.\n\nFeatures:\n- Dependency graph resolution\n- Parallel execution with resource management\n- Intelligent caching with content-based keys\n- Build performance monitoring\n- Integration with existing Makefile commands\n- LLM-powered error explanation\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/monitoring.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Build performance monitoring and metrics collection system",
    "llm_key": "Provides comprehensive build performance tracking, caching analytics, and optimization insights",
    "llm_map": "Performance monitoring system that tracks build metrics and provides optimization recommendations",
    "llm_axiom": "Performance monitoring must be lightweight and provide actionable insights for developers",
    "llm_contract": "Returns structured performance data and optimization recommendations",
    "llm_token": "build-monitoring: Performance tracking and analytics for build system",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Build performance monitoring and metrics collection system\n@llm-key Provides comprehensive build performance tracking, caching analytics, and optimization insights\n@llm-map Performance monitoring system that tracks build metrics and provides optimization recommendations\n@llm-axiom Performance monitoring must be lightweight and provide actionable insights for developers\n@llm-contract Returns structured performance data and optimization recommendations\n@llm-token build-monitoring: Performance tracking and analytics for build system\n\nBuild Performance Monitoring System\n\nProvides comprehensive monitoring and analytics for the enhanced build system:\n- Build time tracking and analysis\n- Cache performance metrics\n- Resource utilization monitoring\n- Performance trend analysis\n- Optimization recommendations\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/developer_experience.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Developer experience enhancements for the enhanced build system",
    "llm_key": "Provides developer-friendly features like progress indicators, quick commands, and better error messages",
    "llm_map": "Developer experience layer that makes the build system more accessible and productive for developers",
    "llm_axiom": "Developer experience must reduce friction and provide clear, actionable feedback",
    "llm_contract": "Returns enhanced user interfaces and developer productivity tools",
    "llm_token": "dev-experience: Developer productivity enhancements for build system",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Developer experience enhancements for the enhanced build system\n@llm-key Provides developer-friendly features like progress indicators, quick commands, and better error messages\n@llm-map Developer experience layer that makes the build system more accessible and productive for developers\n@llm-axiom Developer experience must reduce friction and provide clear, actionable feedback\n@llm-contract Returns enhanced user interfaces and developer productivity tools\n@llm-token dev-experience: Developer productivity enhancements for build system\n\nDeveloper Experience Enhancements\n\nProvides developer-friendly features for the enhanced build system:\n- Progress indicators and status displays\n- Quick setup and development commands\n- Interactive target selection\n- Build status dashboard\n- Error recovery suggestions\n- Performance insights\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/build.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Main entry point for the enhanced Unhinged build system",
    "llm_key": "Provides unified access to enhanced build orchestration with backward compatibility",
    "llm_map": "Entry point script that integrates enhanced build system with existing workflows",
    "llm_axiom": "Build system must maintain backward compatibility while providing enhanced features",
    "llm_contract": "Provides same interface as original build-system.py with enhanced capabilities",
    "llm_token": "build-entry: Main entry point for enhanced build system",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Main entry point for the enhanced Unhinged build system\n@llm-key Provides unified access to enhanced build orchestration with backward compatibility\n@llm-map Entry point script that integrates enhanced build system with existing workflows\n@llm-axiom Build system must maintain backward compatibility while providing enhanced features\n@llm-contract Provides same interface as original build-system.py with enhanced capabilities\n@llm-token build-entry: Main entry point for enhanced build system\n\nEnhanced Build System Entry Point\n\nThis script provides the main entry point for the enhanced build system,\nmaintaining backward compatibility with the original build-system.py while\nadding new capabilities.\n\nFeatures:\n- Backward compatibility with existing build-config.yml\n- Enhanced build orchestration with caching\n- Parallel execution and dependency management\n- Integration with existing Makefile commands\n- LLM-powered error explanation\n\nUsage:\npython build/build.py dev                    # Start development (enhanced)\npython build/build.py build backend-build   # Build specific target\npython build/build.py status                # Show build status\npython build/build.py explain dev-fast      # Explain build target\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/modules/typescript_builder.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "TypeScript/npm build module with webpack optimization and hot reloading",
    "llm_key": "Provides optimized npm builds with webpack, hot module replacement, and intelligent caching",
    "llm_map": "TypeScript build module that integrates with npm/webpack build system and provides enhanced caching",
    "llm_axiom": "TypeScript builds must support hot reloading for development and optimization for production",
    "llm_contract": "Returns BuildModuleResult with JS bundle artifacts and build metrics",
    "llm_token": "typescript-builder: npm/webpack-based build module for TypeScript/React projects",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend TypeScript/npm build module with webpack optimization and hot reloading\n@llm-key Provides optimized npm builds with webpack, hot module replacement, and intelligent caching\n@llm-map TypeScript build module that integrates with npm/webpack build system and provides enhanced caching\n@llm-axiom TypeScript builds must support hot reloading for development and optimization for production\n@llm-contract Returns BuildModuleResult with JS bundle artifacts and build metrics\n@llm-token typescript-builder: npm/webpack-based build module for TypeScript/React projects\n\nTypeScript/npm Build Module\n\nProvides optimized builds for TypeScript projects using npm/webpack with:\n- Hot module replacement for development\n- Bundle optimization for production\n- Source map generation\n- Dependency analysis\n- Asset management\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/modules/__init__.py",
    "line_number": 1,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "contract",
    "llm_legend": "Language-specific build modules for enhanced build orchestration",
    "llm_key": "Provides specialized builders for Kotlin, TypeScript, Python, and Protobuf with caching and optimization",
    "llm_map": "Build module system that integrates with main orchestrator for multi-language support",
    "llm_axiom": "Each language builder must provide consistent interface and caching capabilities",
    "llm_contract": "All builders implement BuildModule interface with build, cache, and validate methods",
    "llm_token": "build-modules: Specialized build handlers for different programming languages",
    "llm_context": null,
    "raw_comment": "@llm-type contract\n@llm-legend Language-specific build modules for enhanced build orchestration\n@llm-key Provides specialized builders for Kotlin, TypeScript, Python, and Protobuf with caching and optimization\n@llm-map Build module system that integrates with main orchestrator for multi-language support\n@llm-axiom Each language builder must provide consistent interface and caching capabilities\n@llm-contract All builders implement BuildModule interface with build, cache, and validate methods\n@llm-token build-modules: Specialized build handlers for different programming languages\n\nEnhanced Build Modules Package\n\nProvides language-specific build modules that integrate with the main build orchestrator\nto provide optimized, cached, and parallel builds for different technologies.\n\nModules:\n- kotlin_builder: Gradle-based Kotlin/JVM builds with incremental compilation\n- typescript_builder: npm/webpack-based TypeScript builds with hot reloading\n- python_builder: pip/poetry-based Python builds with virtual environment management\n- protobuf_builder: Multi-language protobuf generation with smart caching\n- docker_builder: Container build optimization with layer caching\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/modules/python_builder.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Python build module with virtual environment management and dependency caching",
    "llm_key": "Provides optimized Python builds with pip/poetry, virtual environments, and intelligent caching",
    "llm_map": "Python build module that integrates with pip/poetry build systems and provides enhanced caching",
    "llm_axiom": "Python builds must use isolated virtual environments and cache dependencies effectively",
    "llm_contract": "Returns BuildModuleResult with Python package artifacts and build metrics",
    "llm_token": "python-builder: pip/poetry-based build module for Python services",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Python build module with virtual environment management and dependency caching\n@llm-key Provides optimized Python builds with pip/poetry, virtual environments, and intelligent caching\n@llm-map Python build module that integrates with pip/poetry build systems and provides enhanced caching\n@llm-axiom Python builds must use isolated virtual environments and cache dependencies effectively\n@llm-contract Returns BuildModuleResult with Python package artifacts and build metrics\n@llm-token python-builder: pip/poetry-based build module for Python services\n\nPython Build Module\n\nProvides optimized builds for Python projects with:\n- Virtual environment management\n- Dependency caching\n- Package building\n- Test execution\n- Requirements analysis\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "build/modules/kotlin_builder.py",
    "line_number": 3,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Kotlin/Gradle build module with incremental compilation and caching",
    "llm_key": "Provides optimized Gradle builds with parallel execution, incremental compilation, and intelligent caching",
    "llm_map": "Kotlin build module that integrates with Gradle build system and provides enhanced caching",
    "llm_axiom": "Gradle builds must be deterministic and support incremental compilation for fast development",
    "llm_contract": "Returns BuildModuleResult with JAR artifacts and build metrics",
    "llm_token": "kotlin-builder: Gradle-based build module for Kotlin/JVM projects",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Kotlin/Gradle build module with incremental compilation and caching\n@llm-key Provides optimized Gradle builds with parallel execution, incremental compilation, and intelligent caching\n@llm-map Kotlin build module that integrates with Gradle build system and provides enhanced caching\n@llm-axiom Gradle builds must be deterministic and support incremental compilation for fast development\n@llm-contract Returns BuildModuleResult with JAR artifacts and build metrics\n@llm-token kotlin-builder: Gradle-based build module for Kotlin/JVM projects\n\nKotlin/Gradle Build Module\n\nProvides optimized builds for Kotlin projects using Gradle with:\n- Incremental compilation support\n- Parallel execution\n- Build cache integration\n- Dependency analysis\n- JAR artifact management\n\nAuthor: Unhinged Team\nVersion: 2.0.0\nDate: 2025-10-19",
    "context": ""
  },
  {
    "file_path": "frontend/src/services/AudioService.ts",
    "line_number": 41,
    "element_name": "AudioService",
    "language": "typescript",
    "llm_type": "service",
    "llm_legend": "Provides frontend audio processing capabilities including speech-to-text transcription",
    "llm_key": "Uses Fetch API with FormData for audio upload, implements error handling and retry logic",
    "llm_map": "Frontend service layer, communicates with whisper-tts service on port 8000",
    "llm_axiom": "All audio operations must provide user feedback and handle network failures gracefully",
    "llm_contract": "Returns structured responses or throws descriptive errors for UI handling",
    "llm_token": "whisper-service: Python microservice providing speech-to-text capabilities",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Provides frontend audio processing capabilities including speech-to-text transcription\n@llm-key Uses Fetch API with FormData for audio upload, implements error handling and retry logic\n@llm-map Frontend service layer, communicates with whisper-tts service on port 8000\n@llm-axiom All audio operations must provide user feedback and handle network failures gracefully\n@llm-contract Returns structured responses or throws descriptive errors for UI handling\n@llm-token whisper-service: Python microservice providing speech-to-text capabilities\n\nAudio service for pure functional API communication\nFollowing the same pattern as ChatService.ts",
    "context": "export class AudioService {"
  },
  {
    "file_path": "frontend/src/services/AudioService.ts",
    "line_number": 60,
    "element_name": "formData",
    "language": "typescript",
    "llm_type": "function",
    "llm_legend": "Converts user audio recordings to text using AI speech recognition",
    "llm_key": "Creates FormData with audio blob, sends POST to whisper service, handles JSON response",
    "llm_map": "Core transcription function called by UI components, integrates with whisper-tts service",
    "llm_axiom": null,
    "llm_contract": "Accepts audio Blob, returns TranscriptionResponse with text and language, throws on errors",
    "llm_token": null,
    "llm_context": null,
    "raw_comment": "@llm-type function\n@llm-legend Converts user audio recordings to text using AI speech recognition\n@llm-key Creates FormData with audio blob, sends POST to whisper service, handles JSON response\n@llm-map Core transcription function called by UI components, integrates with whisper-tts service\n@llm-contract Accepts audio Blob, returns TranscriptionResponse with text and language, throws on errors\n\nPure function: Transcribe audio blob to text\nInput: Blob (audio data)\nOutput: Promise<TranscriptionResponse>\n\nUses the EXACT same approach as our working HTML implementation",
    "context": "const formData = new FormData();"
  },
  {
    "file_path": "services/vision-ai/main.py",
    "line_number": 2,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Provides AI-powered image analysis using BLIP vision model for user-uploaded content",
    "llm_key": "Loads BLIP model on startup, serves Flask HTTP API on port 8001, implements health checks",
    "llm_map": "Entry point for vision processing pipeline, integrates with backend via HTTP API",
    "llm_axiom": "Vision model must be loaded and ready before accepting any processing requests",
    "llm_contract": "Returns structured analysis JSON or appropriate HTTP error codes for failures",
    "llm_token": "BLIP: Bootstrapping Language-Image Pre-training model for image captioning",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Provides AI-powered image analysis using BLIP vision model for user-uploaded content\n@llm-key Loads BLIP model on startup, serves Flask HTTP API on port 8001, implements health checks\n@llm-map Entry point for vision processing pipeline, integrates with backend via HTTP API\n@llm-axiom Vision model must be loaded and ready before accepting any processing requests\n@llm-contract Returns structured analysis JSON or appropriate HTTP error codes for failures\n@llm-token BLIP: Bootstrapping Language-Image Pre-training model for image captioning\n\nVision AI Service - Main Entry Point\nStarts both Flask HTTP server and gRPC server based on environment variables",
    "context": ""
  },
  {
    "file_path": "services/vision-ai/main.py",
    "line_number": 26,
    "element_name": "start_flask_server",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Starts Flask HTTP server to handle image analysis requests from backend",
    "llm_key": "Binds to all interfaces on port 8001, disables debug mode for production",
    "llm_map": "Called by main thread, serves HTTP endpoints defined in app.py",
    "llm_axiom": null,
    "llm_contract": "Blocks until server shutdown, logs startup status",
    "llm_token": null,
    "llm_context": null,
    "raw_comment": "@llm-type function\n@llm-legend Starts Flask HTTP server to handle image analysis requests from backend\n@llm-key Binds to all interfaces on port 8001, disables debug mode for production\n@llm-map Called by main thread, serves HTTP endpoints defined in app.py\n@llm-contract Blocks until server shutdown, logs startup status",
    "context": "def start_flask_server():"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 2,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "tool",
    "llm_legend": "LLM context warming system for onboarding new AI agents to the Unhinged monorepo",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Provides paginated, structured summaries of codebase culture, vision, and architecture",
    "raw_comment": "@llm-type tool\n@llm-legend LLM context warming system for onboarding new AI agents to the Unhinged monorepo\n@llm-context Provides paginated, structured summaries of codebase culture, vision, and architecture",
    "context": ""
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 17,
    "element_name": "LLMContextWarmer",
    "language": "python",
    "llm_type": "class",
    "llm_legend": "Generates structured context summaries for new LLM agents joining the project",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Converts extracted comments into digestible chunks with pagination support",
    "raw_comment": "@llm-type class\n@llm-legend Generates structured context summaries for new LLM agents joining the project\n@llm-context Converts extracted comments into digestible chunks with pagination support",
    "context": "class LLMContextWarmer:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 37,
    "element_name": "generate_project_overview",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Generates comprehensive project overview from extracted comments",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Creates high-level summary perfect for LLM context warming",
    "raw_comment": "@llm-type function\n@llm-legend Generates comprehensive project overview from extracted comments\n@llm-context Creates high-level summary perfect for LLM context warming",
    "context": "def generate_project_overview(self) -> Dict[str, Any]:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 86,
    "element_name": "_extract_key_components",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Extract key system components with improved name resolution and cross-references",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about unknown element names and missing navigation",
    "raw_comment": "@llm-type function\n@llm-legend Extract key system components with improved name resolution and cross-references\n@llm-context Addresses LLM feedback about unknown element names and missing navigation",
    "context": "def _extract_key_components(self) -> List[Dict[str, str]]:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 123,
    "element_name": "paginate_comments",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Provides paginated access to all extracted comments for detailed review",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Allows LLMs to scroll through codebase comments in digestible chunks",
    "raw_comment": "@llm-type function\n@llm-legend Provides paginated access to all extracted comments for detailed review\n@llm-context Allows LLMs to scroll through codebase comments in digestible chunks",
    "context": "def paginate_comments(self, page: int = 1) -> Dict[str, Any]:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 156,
    "element_name": "_improve_element_name",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Improve element name detection from file paths when element_name is unknown",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about unknown element names in service files",
    "raw_comment": "@llm-type function\n@llm-legend Improve element name detection from file paths when element_name is unknown\n@llm-context Addresses LLM feedback about unknown element names in service files",
    "context": "def _improve_element_name(self, comment: Dict[str, Any]) -> str:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 179,
    "element_name": "_find_related_services",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Find related services through port references, API calls, and integration patterns",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about lack of cross-reference navigation capabilities",
    "raw_comment": "@llm-type function\n@llm-legend Find related services through port references, API calls, and integration patterns\n@llm-context Addresses LLM feedback about lack of cross-reference navigation capabilities",
    "context": "def _find_related_services(self, comment: Dict[str, Any]) -> List[str]:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 232,
    "element_name": "_validate_context_completeness",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Validate that service and component comments have proper context information",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about null llm_context fields where context should exist",
    "raw_comment": "@llm-type function\n@llm-legend Validate that service and component comments have proper context information\n@llm-context Addresses LLM feedback about null llm_context fields where context should exist",
    "context": "def _validate_context_completeness(self, comments: List[Dict[str, Any]]) -> List[Dict[str, str]]:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 254,
    "element_name": "_generate_getting_started_section",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Generate getting started section with setup commands and prerequisites",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about missing getting started section in overview",
    "raw_comment": "@llm-type function\n@llm-legend Generate getting started section with setup commands and prerequisites\n@llm-context Addresses LLM feedback about missing getting started section in overview",
    "context": "def _generate_getting_started_section(self) -> Dict[str, Any]:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 283,
    "element_name": "_extract_dependency_information",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Extract dependency and build system information from configuration files",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about missing dependency/setup information",
    "raw_comment": "@llm-type function\n@llm-legend Extract dependency and build system information from configuration files\n@llm-context Addresses LLM feedback about missing dependency/setup information",
    "context": "def _extract_dependency_information(self) -> Dict[str, Any]:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 316,
    "element_name": "_validate_legend_completeness",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Validate that",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about incomplete/truncated legend entries",
    "raw_comment": "@llm-type function\n@llm-legend Validate that @llm-legend entries are complete and not truncated\n@llm-context Addresses LLM feedback about incomplete/truncated legend entries",
    "context": "def _validate_legend_completeness(self, comments: List[Dict[str, Any]]) -> List[Dict[str, str]]:"
  },
  {
    "file_path": "scripts/docs/llm-context-warmer.py",
    "line_number": 351,
    "element_name": "generate_enhanced_project_overview",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Generate enhanced project overview addressing all LLM feedback for 10/10 rating",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Includes getting started, dependencies, and complete information sections",
    "raw_comment": "@llm-type function\n@llm-legend Generate enhanced project overview addressing all LLM feedback for 10/10 rating\n@llm-context Includes getting started, dependencies, and complete information sections",
    "context": "def generate_enhanced_project_overview(self) -> Dict[str, Any]:"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 2,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "TDD test suite ensuring extraction and validation correctness",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Defines expected behavior for all LLM comment processing functions",
    "raw_comment": "\n@llm-type test\n@llm-legend TDD test suite ensuring extraction and validation correctness\n@llm-context Defines expected behavior for all LLM comment processing functions",
    "context": ""
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 41,
    "element_name": "test_extract_llm_context_from_python",
    "language": "python",
    "llm_type": null,
    "llm_legend": null,
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "from Python docstring.",
    "raw_comment": "Test extraction of @llm-context from Python docstring.",
    "context": "def test_extract_llm_context_from_python(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 42,
    "element_name": "test_extract_llm_context_from_python",
    "language": "python",
    "llm_type": "service",
    "llm_legend": "Processes user requests",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Handles HTTP requests with rate limiting and caching \"\"\" def process(): pass",
    "raw_comment": "\"\"\"\n@llm-type service\n@llm-legend Processes user requests\n@llm-context Handles HTTP requests with rate limiting and caching\n\"\"\"\ndef process():\npass",
    "context": "def test_extract_llm_context_from_python(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 69,
    "element_name": "test_extract_llm_context_from_typescript",
    "language": "python",
    "llm_type": null,
    "llm_legend": null,
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "from TypeScript JSDoc.",
    "raw_comment": "Test extraction of @llm-context from TypeScript JSDoc.",
    "context": "def test_extract_llm_context_from_typescript(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 70,
    "element_name": "test_extract_llm_context_from_typescript",
    "language": "python",
    "llm_type": "component",
    "llm_legend": "React component for user authentication *",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Manages login state and JWT token refresh */ export const AuthComponent = () => { return null; };",
    "raw_comment": "/**\n* @llm-type component\n* @llm-legend React component for user authentication\n* @llm-context Manages login state and JWT token refresh\n*/\nexport const AuthComponent = () => {\nreturn null;\n};",
    "context": "def test_extract_llm_context_from_typescript(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 90,
    "element_name": "test_parse_llm_tags_with_context",
    "language": "python",
    "llm_type": null,
    "llm_legend": null,
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": null,
    "raw_comment": "Test parsing of all tags including @llm-context.",
    "context": "def test_parse_llm_tags_with_context(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 91,
    "element_name": "test_parse_llm_tags_with_context",
    "language": "python",
    "llm_type": "validator",
    "llm_legend": "Validates user input",
    "llm_key": "Checks format and business rules",
    "llm_map": "Part of validation pipeline",
    "llm_axiom": "Never trust user input",
    "llm_contract": "Returns ValidationResult or throws",
    "llm_token": "user-validator",
    "llm_context": "Integrates with form handling and error display",
    "raw_comment": "@llm-type validator\n@llm-legend Validates user input\n@llm-key Checks format and business rules\n@llm-map Part of validation pipeline\n@llm-axiom Never trust user input\n@llm-contract Returns ValidationResult or throws\n@llm-token user-validator\n@llm-context Integrates with form handling and error display",
    "context": "def test_parse_llm_tags_with_context(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 142,
    "element_name": "test_validate_comment_with_context",
    "language": "python",
    "llm_type": null,
    "llm_legend": null,
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": null,
    "raw_comment": "Test validation accepts @llm-context.",
    "context": "def test_validate_comment_with_context(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 203,
    "element_name": "TestLLMContextWarmerImprovements",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test suite for LLM context warmer improvements based on feedback",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Validates element name detection, cross-references, and context completeness",
    "raw_comment": "@llm-type test\n@llm-legend Test suite for LLM context warmer improvements based on feedback\n@llm-context Validates element name detection, cross-references, and context completeness",
    "context": "class TestLLMContextWarmerImprovements(unittest.TestCase):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 210,
    "element_name": "test_element_name_detection_from_service_path",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test element name extraction from services directory paths",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about unknown element names in service files",
    "raw_comment": "@llm-type test\n@llm-legend Test element name extraction from services directory paths\n@llm-context Addresses LLM feedback about unknown element names in service files",
    "context": "def test_element_name_detection_from_service_path(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 241,
    "element_name": "test_element_name_detection_from_python_file",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test element name extraction from Python file names",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Ensures Python modules get proper names instead of unknown",
    "raw_comment": "@llm-type test\n@llm-legend Test element name extraction from Python file names\n@llm-context Ensures Python modules get proper names instead of unknown",
    "context": "def test_element_name_detection_from_python_file(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 270,
    "element_name": "test_find_related_services_by_port_references",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test cross-reference detection between services using port numbers",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about lack of cross-reference navigation",
    "raw_comment": "@llm-type test\n@llm-legend Test cross-reference detection between services using port numbers\n@llm-context Addresses LLM feedback about lack of cross-reference navigation",
    "context": "def test_find_related_services_by_port_references(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 315,
    "element_name": "test_context_completeness_validation",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test validation of context completeness for service components",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about null llm_context fields where context should exist",
    "raw_comment": "@llm-type test\n@llm-legend Test validation of context completeness for service components\n@llm-context Addresses LLM feedback about null llm_context fields where context should exist",
    "context": "def test_context_completeness_validation(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 357,
    "element_name": "test_pagination_data_integrity",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test that pagination maintains complete data integrity across pages",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Ensures no data loss or corruption when browsing paginated comments",
    "raw_comment": "@llm-type test\n@llm-legend Test that pagination maintains complete data integrity across pages\n@llm-context Ensures no data loss or corruption when browsing paginated comments",
    "context": "def test_pagination_data_integrity(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 418,
    "element_name": "TestLLMContextWarmerEnhancements",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test suite for final LLM context warmer enhancements addressing 9/10 feedback",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Validates getting started section, dependency info, and complete legend handling",
    "raw_comment": "@llm-type test\n@llm-legend Test suite for final LLM context warmer enhancements addressing 9/10 feedback\n@llm-context Validates getting started section, dependency info, and complete legend handling",
    "context": "class TestLLMContextWarmerEnhancements(unittest.TestCase):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 425,
    "element_name": "test_getting_started_section_generation",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test generation of getting started section with setup and dependency information",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about missing getting started section in overview",
    "raw_comment": "@llm-type test\n@llm-legend Test generation of getting started section with setup and dependency information\n@llm-context Addresses LLM feedback about missing getting started section in overview",
    "context": "def test_getting_started_section_generation(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 469,
    "element_name": "test_dependency_information_extraction",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test extraction of dependency and setup information from build files",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about missing dependency/setup information in overview",
    "raw_comment": "@llm-type test\n@llm-legend Test extraction of dependency and setup information from build files\n@llm-context Addresses LLM feedback about missing dependency/setup information in overview",
    "context": "def test_dependency_information_extraction(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 506,
    "element_name": "test_complete_legend_validation",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test validation that legends are complete and not truncated",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Addresses LLM feedback about incomplete/truncated",
    "raw_comment": "@llm-type test\n@llm-legend Test validation that legends are complete and not truncated\n@llm-context Addresses LLM feedback about incomplete/truncated @llm-legend entries",
    "context": "def test_complete_legend_validation(self):"
  },
  {
    "file_path": "scripts/docs/test_llm_extraction.py",
    "line_number": 549,
    "element_name": "test_enhanced_overview_with_getting_started",
    "language": "python",
    "llm_type": "test",
    "llm_legend": "Test that enhanced overview includes getting started and dependency sections",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Validates complete overview addresses all LLM feedback points for 10/10 rating",
    "raw_comment": "@llm-type test\n@llm-legend Test that enhanced overview includes getting started and dependency sections\n@llm-context Validates complete overview addresses all LLM feedback points for 10/10 rating",
    "context": "def test_enhanced_overview_with_getting_started(self):"
  },
  {
    "file_path": "scripts/docs/extract-llm-comments.py",
    "line_number": 2,
    "element_name": "unknown",
    "language": "python",
    "llm_type": null,
    "llm_legend": null,
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": null,
    "raw_comment": "LLM Comment Extraction System\n\nParses @llm-* tags from code comments across all programming languages\nin the Unhinged monorepo and generates architectural documentation.",
    "context": ""
  },
  {
    "file_path": "scripts/docs/extract-llm-comments.py",
    "line_number": 132,
    "element_name": "_parse_llm_tags",
    "language": "python",
    "llm_type": null,
    "llm_legend": null,
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": null,
    "raw_comment": "Parse @llm-* tags from comment text",
    "context": "def _parse_llm_tags(self, comment_text: str, file_path: str, line_number: int,"
  },
  {
    "file_path": "scripts/docs/extract-llm-comments.py",
    "line_number": 243,
    "element_name": "_parse_llm_tags",
    "language": "python",
    "llm_type": null,
    "llm_legend": null,
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": null,
    "raw_comment": "Parse @llm-* tags from Python docstring",
    "context": "def _parse_llm_tags(self, comment_text: str, file_path: str, line_number: int,"
  },
  {
    "file_path": "scripts/docs/extract-llm-comments.py",
    "line_number": 485,
    "element_name": "generate_architectural_overview",
    "language": "python",
    "llm_type": null,
    "llm_legend": null,
    "llm_key": null,
    "llm_map": "comments",
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": null,
    "raw_comment": "Generate architectural overview from @llm-map comments",
    "context": "def generate_architectural_overview(self) -> str:"
  },
  {
    "file_path": "scripts/docs/extract-llm-comments.py",
    "line_number": 573,
    "element_name": "extract_comments_from_file",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Extracts all",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "TDD interface function for testing individual file processing",
    "raw_comment": "\n@llm-type function\n@llm-legend Extracts all @llm-* comments from a single source file using appropriate language parser\n@llm-context TDD interface function for testing individual file processing",
    "context": "def extract_comments_from_file(file_path: str) -> List[LLMComment]:"
  },
  {
    "file_path": "scripts/docs/extract-llm-comments.py",
    "line_number": 594,
    "element_name": "extract_comments_from_codebase",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Extracts all",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "TDD interface function for testing full codebase processing",
    "raw_comment": "\n@llm-type function\n@llm-legend Extracts all @llm-* comments from entire codebase using multi-language parsers\n@llm-context TDD interface function for testing full codebase processing",
    "context": "def extract_comments_from_codebase(root_path: Path) -> List[LLMComment]:"
  },
  {
    "file_path": "scripts/docs/extract-llm-comments.py",
    "line_number": 604,
    "element_name": "parse_llm_tags",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Parses individual",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "TDD interface function for testing tag parsing logic",
    "raw_comment": "\n@llm-type function\n@llm-legend Parses individual @llm-* tags from comment text using regex patterns\n@llm-context TDD interface function for testing tag parsing logic",
    "context": "def parse_llm_tags(text: str) -> Dict[str, str]:"
  },
  {
    "file_path": "scripts/docs/extract-llm-comments.py",
    "line_number": 634,
    "element_name": "save_extraction_results",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Saves extracted comments to JSON with metadata",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "TDD interface function for testing result serialization",
    "raw_comment": "\n@llm-type function\n@llm-legend Saves extracted comments to JSON with metadata\n@llm-context TDD interface function for testing result serialization",
    "context": "def save_extraction_results(comments: List[LLMComment], output_path: Path) -> Dict:"
  },
  {
    "file_path": "scripts/docs/validate-llm-comments.py",
    "line_number": 2,
    "element_name": "unknown",
    "language": "python",
    "llm_type": null,
    "llm_legend": null,
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": null,
    "raw_comment": "LLM Comment Validation System\n\nValidates consistency and quality of @llm-* comments across the codebase.\nIntegrates with the existing documentation validation workflow.",
    "context": ""
  },
  {
    "file_path": "scripts/docs/validate-llm-comments.py",
    "line_number": 287,
    "element_name": "validate_comment",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Validates individual comment for completeness and quality",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "TDD interface function for testing single comment validation",
    "raw_comment": "\n@llm-type function\n@llm-legend Validates individual comment for completeness and quality\n@llm-context TDD interface function for testing single comment validation",
    "context": "def validate_comment(comment) -> List[Dict]:"
  },
  {
    "file_path": "scripts/docs/validate-llm-comments.py",
    "line_number": 299,
    "element_name": "validate_all_comments",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Validates batch of comments and returns summary",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "TDD interface function for testing batch validation",
    "raw_comment": "\n@llm-type function\n@llm-legend Validates batch of comments and returns summary\n@llm-context TDD interface function for testing batch validation",
    "context": "def validate_all_comments(comments: List) -> Dict:"
  },
  {
    "file_path": "scripts/docs/validate-llm-comments.py",
    "line_number": 324,
    "element_name": "check_required_tags",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Validates comment has all required tags for its type",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "TDD interface function for testing required tag validation",
    "raw_comment": "\n@llm-type function\n@llm-legend Validates comment has all required tags for its type\n@llm-context TDD interface function for testing required tag validation",
    "context": "def check_required_tags(comment) -> List[Dict]:"
  },
  {
    "file_path": "scripts/docs/validate-llm-comments.py",
    "line_number": 351,
    "element_name": "check_tag_format",
    "language": "python",
    "llm_type": "function",
    "llm_legend": "Validates tag content meets quality standards",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "TDD interface function for testing tag format validation",
    "raw_comment": "\n@llm-type function\n@llm-legend Validates tag content meets quality standards\n@llm-context TDD interface function for testing tag format validation",
    "context": "def check_tag_format(comment) -> List[Dict]:"
  },
  {
    "file_path": "scripts/docs/llm_types.py",
    "line_number": 2,
    "element_name": "unknown",
    "language": "python",
    "llm_type": "contract",
    "llm_legend": "Defines data structures and interfaces for LLM comment extraction/validation",
    "llm_key": null,
    "llm_map": null,
    "llm_axiom": null,
    "llm_contract": null,
    "llm_token": null,
    "llm_context": "Central type system ensuring consistency across extraction and validation pipeline",
    "raw_comment": "\n@llm-type contract\n@llm-legend Defines data structures and interfaces for LLM comment extraction/validation\n@llm-context Central type system ensuring consistency across extraction and validation pipeline",
    "context": ""
  },
  {
    "file_path": "backend/temp-disabled/infrastructure/vision/HttpVisionProcessingService.kt",
    "line_number": 68,
    "element_name": "HttpVisionProcessingService",
    "language": "kotlin",
    "llm_type": "service",
    "llm_legend": "Enables backend to request AI-powered image analysis from vision-ai microservice",
    "llm_key": "Uses Ktor HTTP client with JSON serialization, implements retry logic and error handling",
    "llm_map": "Infrastructure layer implementation, called by application services, connects to vision-ai on port 8001",
    "llm_axiom": "All HTTP calls must have timeouts and proper error handling to prevent system hangs",
    "llm_contract": "Returns VisionResult on success or throws VisionProcessingException on failures",
    "llm_token": "vision-ai-service: Python microservice running BLIP model for image analysis",
    "llm_context": null,
    "raw_comment": "@llm-type service\n@llm-legend Enables backend to request AI-powered image analysis from vision-ai microservice\n@llm-key Uses Ktor HTTP client with JSON serialization, implements retry logic and error handling\n@llm-map Infrastructure layer implementation, called by application services, connects to vision-ai on port 8001\n@llm-axiom All HTTP calls must have timeouts and proper error handling to prevent system hangs\n@llm-contract Returns VisionResult on success or throws VisionProcessingException on failures\n@llm-token vision-ai-service: Python microservice running BLIP model for image analysis\n\nHTTP client implementation of VisionProcessingService\n\nCommunicates with the Python vision-ai service via HTTP API",
    "context": "class HttpVisionProcessingService("
  }
]