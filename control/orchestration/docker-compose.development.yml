version: '3.8'

services:
  backend:
    build: ./backend
    container_name: backend-service
    environment:
      - DB_HOST=database
      - DB_PORT=26257
      - DB_USER=root
      - DB_PASSWORD=
      - DB_NAME=unhinged_db
      - OLLAMA_HOST=http://llm:11434
      - KAFKA_BROKERS=kafka:29092
    ports:
      - "8082:8080"
    depends_on:
      - database
      - llm

  # CDC Service (Python FastAPI)
  cdc-service:
    build: ./backend/cdc-service
    container_name: cdc-service
    environment:
      - KAFKA_BROKERS=kafka:29092
      - DATABASE_URL=postgresql://root@database:26257/unhinged_db?sslmode=disable
    ports:
      - "8083:8081"
    depends_on:
      - database
      - kafka

  frontend:
    build: ./frontend
    container_name: frontend-service
    ports:
      - "3000:80"
    depends_on:
      - backend

  llm:
    build: ./llm
    container_name: ollama-service
    volumes:
      - llm-models:/models  # Mount the volume to persist the model
    ports:
      - "11534:11434"
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    environment:
      # - NVIDIA_VISIBLE_DEVICES=all
      # - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # - OLLAMA_GPU_MEMORY_FRACTION=0.8
      # - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_HOST=0.0.0.0

  # @llm-type config
  # @llm-legend Docker service configuration for AI-powered image analysis microservice
  # @llm-key Defines Python container with BLIP model, Flask HTTP server, and persistent model storage
  # @llm-map Part of microservices architecture, connects backend to vision processing capabilities
  # @llm-axiom Vision service must be accessible on port 8001 for backend integration
  # @llm-contract Service must respond to health checks within 30 seconds and handle image uploads
  # @llm-token vision-models: Docker volume for persistent transformer model cache
  vision-ai:
    build: ./services/vision-ai
    container_name: vision-ai-service
    environment:
      - ENABLE_FLASK=true
      - ENABLE_GRPC=false
      - VISION_MODEL=Salesforce/blip-image-captioning-base
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
    ports:
      - "8101:8001"
    volumes:
      - vision-models:/root/.cache/transformers
      - image-uploads:/app/uploads

  # @llm-key Speech-to-Text service for voice transcription using Whisper
  # @llm-map Essential for voice recording functionality in control plane
  # @llm-axiom Service must be accessible on port 8000 for voice test page
  # @llm-contract Service must respond to health checks and handle audio uploads
  # @llm-token whisper-models: Docker volume for persistent Whisper model cache
  speech-to-text:
    build:
      context: ./services/speech-to-text
      dockerfile: Dockerfile
    container_name: speech-to-text-service
    ports:
      - "8100:8000"  # HTTP API
    environment:
      - WHISPER_MODEL=base
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
    volumes:
      - whisper-models:/root/.cache/whisper
      - audio-uploads:/app/uploads
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    restart: unless-stopped

  # @llm-key Text-to-Speech service for voice synthesis using Coqui TTS
  # @llm-map Provides local neural voice synthesis capabilities
  # @llm-axiom Service must be accessible on port 8002 for TTS functionality
  # @llm-contract Service must respond to health checks and generate audio files
  # @llm-token tts-models: Docker volume for persistent TTS model cache
  text-to-speech:
    build:
      context: ./services/text-to-speech
      dockerfile: Dockerfile
    container_name: text-to-speech-service
    ports:
      - "8002:8001"  # HTTP API
    environment:
      - TTS_MODEL_NAME=tts_models/en/ljspeech/tacotron2-DDC
      - TTS_CACHE_DIR=/app/models
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
    volumes:
      - tts-models:/app/models
      - audio-outputs:/app/outputs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    restart: unless-stopped

  database:
    image: cockroachdb/cockroach:v23.1.11
    container_name: cockroachdb-main
    environment:
      COCKROACH_DATABASE: unhinged_db
      COCKROACH_USER: root
    ports:
      - "26357:26257"  # SQL port (PostgreSQL wire protocol compatible)
      - "8082:8080"    # Admin UI
    command: start-single-node --insecure --store=attrs=ssd,path=/cockroach/cockroach-data --listen-addr=127.0.0.1:26257 --http-addr=127.0.0.1:8080
    volumes:
      - cockroachdb-data:/cockroach/cockroach-data
      - ./sql/init-minimal.sql:/docker-entrypoint-initdb.d/init-cdc.sql
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health?ready=1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  # ==========================================================================
  # Redis - Cache and Session Store
  # ==========================================================================
  redis:
    image: redis:7.2-alpine
    container_name: unhinged-redis
    ports:
      - "6479:6379"
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # MongoDB removed - using Cassandra for NoSQL/column store instead

  # ==========================================================================
  # Elasticsearch - General Text Search & Full-Text Indexing
  # ==========================================================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: unhinged-elasticsearch
    ports:
      - "9300:9200"
      - "9400:9300"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - bootstrap.memory_lock=true
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # Weaviate - Vector Database
  # ==========================================================================
  weaviate:
    image: semitechnologies/weaviate:1.22.4
    container_name: unhinged-weaviate
    ports:
      - "8083:8080"  # Avoid conflicts with CockroachDB and Spark
    environment:
      - QUERY_DEFAULTS_LIMIT=25
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - PERSISTENCE_DATA_PATH=/var/lib/weaviate
      - DEFAULT_VECTORIZER_MODULE=none
      - ENABLE_MODULES=text2vec-openai,text2vec-cohere,text2vec-huggingface,ref2vec-centroid,generative-openai,qna-openai
      - CLUSTER_HOSTNAME=node1
    volumes:
      - weaviate-data:/var/lib/weaviate
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # Cassandra - NoSQL and Column-based Storage
  # ==========================================================================
  cassandra:
    image: cassandra:4.1
    container_name: unhinged-cassandra
    ports:
      - "9142:9042"
    environment:
      - CASSANDRA_CLUSTER_NAME=UnhingedCluster
      - CASSANDRA_DC=datacenter1
      - CASSANDRA_RACK=rack1
      - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
      - MAX_HEAP_SIZE=2G
      - HEAP_NEWSIZE=400M
    volumes:
      - cassandra-data:/var/lib/cassandra
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "cqlsh", "-e", "describe keyspaces"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ==========================================================================
  # Chroma - Open Source Vector Database
  # ==========================================================================
  chroma:
    image: chromadb/chroma:latest
    container_name: unhinged-chroma
    ports:
      - "8084:8000"
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - PERSIST_DIRECTORY=/chroma/data
    volumes:
      - chroma-data:/chroma/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # Apache Flink - Stream Processing Engine (Polyglot Events)
  # ==========================================================================
  flink-jobmanager:
    image: flink:latest
    container_name: flink-jobmanager
    ports:
      - "8083:8081"  # Flink Web UI
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    command: jobmanager
    volumes:
      - flink-data:/opt/flink/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/overview"]
      interval: 30s
      timeout: 10s
      retries: 3

  flink-taskmanager:
    image: flink:latest
    container_name: flink-taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    command: taskmanager
    volumes:
      - flink-data:/opt/flink/data
    depends_on:
      - flink-jobmanager
    restart: unless-stopped

  # ==========================================================================
  # Apache Spark - Data Lake Processing Engine (Batch)
  # ==========================================================================
  spark-master:
    image: apache/spark:3.5.0
    container_name: unhinged-spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_MASTER_WEBUI_PORT=8082
    ports:
      - "8182:8082"  # Spark Master Web UI (avoid CockroachDB conflict)
      - "7077:7077"  # Spark Master port
    volumes:
      - ./data-lake:/opt/spark/data-lake  # Direct filesystem mount
      - ./data-lake/warehouse:/opt/spark/warehouse  # Iceberg warehouse
      - ./data-lake/logs:/opt/spark/logs  # Processing logs
      - spark-work:/opt/spark/work  # Spark working directory
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082"]
      interval: 30s
      timeout: 10s
      retries: 3

  spark-worker:
    image: apache/spark:3.5.0
    container_name: unhinged-spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=6g  # Optimized for 16-core AMD
      - SPARK_WORKER_CORES=8    # Half cores for worker
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./data-lake:/opt/spark/data-lake  # Same filesystem mount
      - ./data-lake/warehouse:/opt/spark/warehouse
      - ./data-lake/logs:/opt/spark/logs
      - spark-work:/opt/spark/work
    depends_on:
      - spark-master
    restart: unless-stopped

  # ==========================================================================
  # Apache Iceberg - Data Lake Table Format (Filesystem-Native)
  # ==========================================================================
  # Note: Iceberg tables stored directly on local filesystem
  # No separate service needed - integrated with Spark

  # Kafka for CDC events
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2281:2181"

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_NUM_PARTITIONS: 1
    ports:
      - "9192:9092"

  # Kafka UI for debugging
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: local-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    ports:
      - "8085:8080"

volumes:
  llm-models:  # Declare the volume to store the model data
  cockroachdb-data:  # CockroachDB distributed SQL data
  redis-data:  # Redis cache and session data
  cassandra-data:  # Cassandra NoSQL and column data
  chroma-data:  # Chroma vector database data
  weaviate-data:  # Weaviate vector database data
  elasticsearch-data:  # Elasticsearch full-text search data
  flink-data:  # Flink stream processing data
  # mongodb-data removed - using Cassandra instead
  spark-work:  # Spark working directory
  vision-models:  # Store vision model cache
  image-uploads:  # Store uploaded images
  whisper-models:  # Store Whisper model cache
  audio-uploads:  # Store uploaded audio files
  tts-models:  # Store TTS model cache
  audio-outputs:  # Store generated audio files
