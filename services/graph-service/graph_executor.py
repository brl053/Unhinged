#!/usr/bin/env python3
"""
@llm-type service.core
@llm-does Graph execution engine - orchestrates AI service workflows
"""

import asyncio
import sys
import uuid
from collections.abc import AsyncGenerator
from datetime import datetime
from pathlib import Path

# Add generated proto clients to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "generated" / "python" / "clients"))

try:
    from google.protobuf import struct_pb2, timestamp_pb2
    from unhinged_proto_clients import common_pb2, graph_service_pb2
except ImportError as e:
    print(f"âŒ Proto clients not found: {e}")
    print("Run 'make generate' to generate proto clients")
    sys.exit(1)

from events import create_service_logger
from node_executors import NodeExecutorFactory

# Initialize event logger
events = create_service_logger("graph-executor", "1.0.0")


class GraphExecutor:
    """Core Graph execution engine"""

    def __init__(self):
        self.graphs: dict[str, graph_service_pb2.Graph] = {}
        self.executions: dict[str, dict] = {}
        self.node_factory = NodeExecutorFactory()
        events.info("Graph executor initialized")

    async def create_graph(self, graph: graph_service_pb2.Graph) -> str:
        """Create and store a Graph definition"""
        if not graph.id:
            graph.id = str(uuid.uuid4())

        # Validate Graph structure
        await self._validate_graph(graph)

        # Store Graph
        self.graphs[graph.id] = graph

        events.info(
            "Graph created and stored",
            {
                "graph_id": graph.id,
                "name": graph.name,
                "node_count": len(graph.nodes),
                "edge_count": len(graph.edges),
            },
        )

        return graph.id

    async def get_graph(self, graph_id: str) -> graph_service_pb2.Graph:
        """Retrieve a Graph definition"""
        if graph_id not in self.graphs:
            raise ValueError(f"Graph not found: {graph_id}")

        return self.graphs[graph_id]

    async def list_graphs(self, pagination, filters, graph_type) -> list[graph_service_pb2.Graph]:
        """List all Graph definitions"""
        # Simple implementation - return all Graphs
        # TODO: Implement pagination and filtering
        graphs = list(self.graphs.values())

        # Filter by graph_type if specified
        if graph_type and graph_type != graph_service_pb2.GRAPH_TYPE_UNSPECIFIED:
            graphs = [g for g in graphs if g.graph_type == graph_type]

        return graphs

    async def delete_graph(self, graph_id: str):
        """Delete a Graph definition"""
        if graph_id not in self.graphs:
            raise ValueError(f"Graph not found: {graph_id}")

        # Check for running executions
        running_executions = [
            exec_id
            for exec_id, exec_data in self.executions.items()
            if exec_data.get("graph_id") == graph_id and exec_data.get("status") == "RUNNING"
        ]

        if running_executions:
            raise ValueError(f"Cannot delete Graph with running executions: {running_executions}")

        del self.graphs[graph_id]
        events.info("Graph deleted", {"graph_id": graph_id})

    async def execute_graph(self, graph_id: str, input_data, execution_id: str | None = None) -> str:
        """Start Graph execution"""
        if graph_id not in self.graphs:
            raise ValueError(f"Graph not found: {graph_id}")

        if not execution_id:
            execution_id = str(uuid.uuid4())

        graph = self.graphs[graph_id]

        # Initialize execution state
        execution_state = {
            "execution_id": execution_id,
            "graph_id": graph_id,
            "status": "RUNNING",
            "started_at": datetime.utcnow().isoformat(),
            "input_data": input_data,
            "node_states": {},
            "events": [],
        }

        self.executions[execution_id] = execution_state

        # Start execution in background
        asyncio.create_task(self._execute_graph_async(graph, execution_state))

        events.info(
            "Graph execution initiated",
            {"graph_id": graph_id, "execution_id": execution_id},
        )

        return execution_id

    async def _execute_graph_async(self, graph: graph_service_pb2.Graph, execution_state: dict):
        """Execute Graph asynchronously"""
        try:
            execution_id = execution_state["execution_id"]

            # Add execution started event
            await self._add_execution_event(execution_state, "EXECUTION_STARTED", None, {})

            # Build execution graph
            node_map = {node.id: node for node in graph.nodes}
            edge_map = self._build_edge_map(graph.edges)

            # Execute nodes in topological order
            executed_nodes = set()

            while len(executed_nodes) < len(graph.nodes):
                # Find nodes ready to execute (all dependencies satisfied)
                ready_nodes = []
                for node in graph.nodes:
                    if node.id not in executed_nodes:
                        dependencies = edge_map.get(node.id, [])
                        if all(dep in executed_nodes for dep in dependencies):
                            ready_nodes.append(node)

                if not ready_nodes:
                    raise RuntimeError("Circular dependency detected or no ready nodes")

                # Execute ready nodes in parallel
                tasks = []
                for node in ready_nodes:
                    task = self._execute_node(node, execution_state, node_map)
                    tasks.append(task)

                # Wait for all nodes to complete
                results = await asyncio.gather(*tasks, return_exceptions=True)

                # Check for failures
                for i, result in enumerate(results):
                    node = ready_nodes[i]
                    if isinstance(result, Exception):
                        await self._handle_node_failure(node, execution_state, result)
                        return
                    else:
                        executed_nodes.add(node.id)

            # Mark execution as completed
            execution_state["status"] = "COMPLETED"
            execution_state["completed_at"] = datetime.utcnow().isoformat()
            await self._add_execution_event(execution_state, "EXECUTION_COMPLETED", None, {})

            events.info("Graph execution completed", {"execution_id": execution_id})

        except Exception as e:
            execution_state["status"] = "FAILED"
            execution_state["error_message"] = str(e)
            execution_state["completed_at"] = datetime.utcnow().isoformat()
            await self._add_execution_event(execution_state, "EXECUTION_FAILED", None, {"error": str(e)})

            events.error(
                "Graph execution failed",
                exception=e,
                metadata={"execution_id": execution_state["execution_id"]},
            )

    async def _execute_node(self, node: graph_service_pb2.Node, execution_state: dict, node_map: dict):
        """Execute a single node"""
        node_id = node.id

        try:
            # Add node started event
            await self._add_execution_event(execution_state, "NODE_STARTED", node_id, {})

            # Get node executor
            executor = self.node_factory.get_executor(node.type)

            # Collect input data from previous nodes
            input_data = await self._collect_node_inputs(node, execution_state, node_map)

            # Execute node
            output_data = await executor.execute(node, input_data)

            # Store node result
            execution_state["node_states"][node_id] = {
                "status": "COMPLETED",
                "started_at": datetime.utcnow().isoformat(),
                "completed_at": datetime.utcnow().isoformat(),
                "output_data": output_data,
            }

            # Add node completed event
            await self._add_execution_event(execution_state, "NODE_COMPLETED", node_id, output_data)

            events.info(
                "Node executed successfully",
                {
                    "node_id": node_id,
                    "node_type": node.type,
                    "execution_id": execution_state["execution_id"],
                },
            )

        except Exception as e:
            execution_state["node_states"][node_id] = {
                "status": "FAILED",
                "started_at": datetime.utcnow().isoformat(),
                "completed_at": datetime.utcnow().isoformat(),
                "error_message": str(e),
            }

            await self._add_execution_event(execution_state, "NODE_FAILED", node_id, {"error": str(e)})
            raise e

    async def _collect_node_inputs(self, node: graph_service_pb2.Node, execution_state: dict, node_map: dict) -> dict:
        """Collect input data for a node from its dependencies"""
        # Simple implementation - return execution input data for now
        # TODO: Implement proper edge-based data flow
        return execution_state.get("input_data", {})

    def _build_edge_map(self, edges) -> dict[str, list[str]]:
        """Build a map of node dependencies from edges"""
        edge_map = {}
        for edge in edges:
            target = edge.target_node_id
            source = edge.source_node_id

            if target not in edge_map:
                edge_map[target] = []
            edge_map[target].append(source)

        return edge_map

    async def _add_execution_event(
        self,
        execution_state: dict,
        event_type: str,
        node_id: str | None,
        event_data: dict,
    ):
        """Add an event to the execution log"""
        event = {
            "timestamp": datetime.utcnow().isoformat(),
            "event_type": event_type,
            "node_id": node_id or "",
            "event_data": event_data,
        }
        execution_state["events"].append(event)

    async def _handle_node_failure(self, node: graph_service_pb2.Node, execution_state: dict, error: Exception):
        """Handle node execution failure"""
        execution_state["status"] = "FAILED"
        execution_state["error_message"] = f"Node {node.id} failed: {str(error)}"
        execution_state["completed_at"] = datetime.utcnow().isoformat()

        await self._add_execution_event(
            execution_state,
            "EXECUTION_FAILED",
            None,
            {"failed_node": node.id, "error": str(error)},
        )

    async def _validate_graph(self, graph: graph_service_pb2.Graph):
        """Validate Graph structure based on graph_type"""
        if not graph.nodes:
            raise ValueError("Graph must have at least one node")

        # Check for duplicate node IDs
        node_ids = [node.id for node in graph.nodes]
        if len(node_ids) != len(set(node_ids)):
            raise ValueError("Duplicate node IDs found")

        # Validate edges reference existing nodes
        for edge in graph.edges:
            if edge.source_node_id not in node_ids:
                raise ValueError(f"Edge references non-existent source node: {edge.source_node_id}")
            if edge.target_node_id not in node_ids:
                raise ValueError(f"Edge references non-existent target node: {edge.target_node_id}")

        # Validate based on graph type
        if graph.graph_type == graph_service_pb2.DAG:
            # DAG validation: detect cycles
            if self._has_cycle(graph.nodes, graph.edges):
                raise ValueError("DAG graph type does not allow cycles")
        elif graph.graph_type == graph_service_pb2.TREE:
            # Tree validation: each node (except root) has exactly one parent
            if not self._is_tree(graph.nodes, graph.edges):
                raise ValueError("TREE graph type requires strict tree structure")
        # CYCLIC, CYCLIC_WITH_BREAKERS, UNRESTRICTED: no additional validation needed

    def _has_cycle(self, nodes, edges) -> bool:
        """Detect cycles in graph using DFS"""
        # Build adjacency list
        adj = {node.id: [] for node in nodes}
        for edge in edges:
            adj[edge.source_node_id].append(edge.target_node_id)

        visited = set()
        rec_stack = set()

        def dfs(node_id):
            visited.add(node_id)
            rec_stack.add(node_id)

            for neighbor in adj.get(node_id, []):
                if neighbor not in visited:
                    if dfs(neighbor):
                        return True
                elif neighbor in rec_stack:
                    return True

            rec_stack.remove(node_id)
            return False

        for node in nodes:
            if node.id not in visited:
                if dfs(node.id):
                    return True

        return False

    def _is_tree(self, nodes, edges) -> bool:
        """Check if graph is a valid tree structure"""
        if not nodes:
            return True

        # Count incoming edges for each node
        incoming_count = {node.id: 0 for node in nodes}
        for edge in edges:
            incoming_count[edge.target_node_id] += 1

        # Tree must have exactly one root (0 incoming edges)
        roots = [nid for nid, count in incoming_count.items() if count == 0]
        if len(roots) != 1:
            return False

        # All other nodes must have exactly one incoming edge
        for nid, count in incoming_count.items():
            if nid != roots[0] and count != 1:
                return False

        # Must not have cycles
        return not self._has_cycle(nodes, edges)

    async def stream_execution(self, execution_id: str) -> AsyncGenerator[graph_service_pb2.ExecutionEvent, None]:
        """Stream execution events"""
        if execution_id not in self.executions:
            raise ValueError(f"Execution not found: {execution_id}")

        execution_state = self.executions[execution_id]
        last_event_index = 0

        while execution_state.get("status") in ["RUNNING", "PENDING"]:
            events_list = execution_state.get("events", [])

            # Yield new events
            for i in range(last_event_index, len(events_list)):
                event_data = events_list[i]

                event = graph_service_pb2.ExecutionEvent()
                event.execution_id = execution_id

                # Convert timestamp
                timestamp = timestamp_pb2.Timestamp()
                timestamp.FromDatetime(datetime.fromisoformat(event_data["timestamp"]))
                event.timestamp.CopyFrom(timestamp)

                # Set event type
                event_type_map = {
                    "EXECUTION_STARTED": graph_service_pb2.EXECUTION_STARTED,
                    "NODE_STARTED": graph_service_pb2.NODE_STARTED,
                    "NODE_COMPLETED": graph_service_pb2.NODE_COMPLETED,
                    "NODE_FAILED": graph_service_pb2.NODE_FAILED,
                    "EXECUTION_COMPLETED": graph_service_pb2.EXECUTION_COMPLETED,
                    "EXECUTION_FAILED": graph_service_pb2.EXECUTION_FAILED,
                    "EXECUTION_CANCELLED": graph_service_pb2.EXECUTION_CANCELLED,
                }
                event.event_type = event_type_map.get(event_data["event_type"], 0)
                event.node_id = event_data.get("node_id", "")

                # Convert event data to Struct
                if event_data.get("event_data"):
                    struct_data = struct_pb2.Struct()
                    struct_data.update(event_data["event_data"])
                    event.event_data.CopyFrom(struct_data)

                yield event

            last_event_index = len(events_list)
            await asyncio.sleep(0.1)  # Small delay to avoid busy waiting

        # Yield final events if execution completed
        events_list = execution_state.get("events", [])
        for i in range(last_event_index, len(events_list)):
            event_data = events_list[i]
            # ... (same event creation logic as above)

    async def get_execution(self, execution_id: str) -> graph_service_pb2.GetExecutionResponse:
        """Get execution status and results"""
        if execution_id not in self.executions:
            raise ValueError(f"Execution not found: {execution_id}")

        execution_state = self.executions[execution_id]

        response = graph_service_pb2.GetExecutionResponse()
        response.execution_id = execution_id
        response.graph_id = execution_state["graph_id"]

        # Map status
        status_map = {
            "PENDING": graph_service_pb2.PENDING,
            "RUNNING": graph_service_pb2.RUNNING,
            "COMPLETED": graph_service_pb2.COMPLETED,
            "FAILED": graph_service_pb2.FAILED,
            "CANCELLED": graph_service_pb2.CANCELLED,
        }
        response.status = status_map.get(execution_state["status"], graph_service_pb2.EXECUTION_STATUS_UNSPECIFIED)

        # Set timestamps
        if execution_state.get("started_at"):
            started_at = timestamp_pb2.Timestamp()
            started_at.FromDatetime(datetime.fromisoformat(execution_state["started_at"]))
            response.started_at.CopyFrom(started_at)

        if execution_state.get("completed_at"):
            completed_at = timestamp_pb2.Timestamp()
            completed_at.FromDatetime(datetime.fromisoformat(execution_state["completed_at"]))
            response.completed_at.CopyFrom(completed_at)

        # Set error message if failed
        if execution_state.get("error_message"):
            response.error_message = execution_state["error_message"]

        return response

    async def cancel_execution(self, execution_id: str):
        """Cancel a running execution"""
        if execution_id not in self.executions:
            raise ValueError(f"Execution not found: {execution_id}")

        execution_state = self.executions[execution_id]

        if execution_state["status"] not in ["RUNNING", "PENDING"]:
            raise ValueError(f"Cannot cancel execution in status: {execution_state['status']}")

        execution_state["status"] = "CANCELLED"
        execution_state["completed_at"] = datetime.utcnow().isoformat()

        await self._add_execution_event(execution_state, "EXECUTION_CANCELLED", None, {})

        events.info("Execution cancelled", {"execution_id": execution_id})
