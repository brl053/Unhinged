syntax = "proto3";

package multimodal;

import "common.proto";

option java_package = "com.unhinged.multimodal.grpc";
option java_outer_classname = "VisionServiceProto";
option java_multiple_files = true;

// Vision AI Service - Pure model inference operations
service VisionService {
  // Perform image inference using specified model
  rpc Infer(VisionInferenceRequest) returns (VisionInferenceResponse);
  
  // Get list of available vision models
  rpc GetAvailableModels(Empty) returns (ModelsResponse);
  
  // Health check for service availability
  rpc GetHealth(Empty) returns (HealthResponse);
  
  // Get model performance metrics
  rpc GetModelMetrics(ModelMetricsRequest) returns (ModelMetricsResponse);
}

// Request for vision inference
message VisionInferenceRequest {
  // Raw image data (JPEG, PNG, etc.)
  bytes image_data = 1;
  
  // Model to use for inference (e.g., "qwen2-vl", "blip-base")
  string model = 2;
  
  // Analysis prompt for the model
  string prompt = 3;
  
  // Type of analysis (screenshot, natural_image, document, ui_component)
  string analysis_type = 4;
  
  // Maximum tokens for response
  int32 max_tokens = 5;
  
  // Temperature for generation (0.0 to 1.0)
  float temperature = 6;
  
  // Additional inference parameters
  map<string, string> parameters = 7;
}

// Response from vision inference
message VisionInferenceResponse {
  // Generated description of the image
  string description = 1;
  
  // Confidence score (0.0 to 1.0)
  double confidence = 2;
  
  // Model that was actually used
  string model_used = 3;
  
  // Processing time in seconds
  double processing_time = 4;
  
  // Additional metadata from inference
  map<string, string> metadata = 5;
  
  // Extracted text from OCR (if applicable)
  string extracted_text = 6;
  
  // Detected UI elements
  repeated UIElement ui_elements = 7;
  
  // Generated tags/labels
  repeated string tags = 8;
  
  // Error message if inference failed
  string error = 9;
  
  // Success status
  bool success = 10;
}

// UI element detected in image
message UIElement {
  // Type of UI element (button, input, text, etc.)
  string type = 1;
  
  // Confidence of detection (0.0 to 1.0)
  double confidence = 2;
  
  // Bounding box coordinates
  ElementBounds bounds = 3;
  
  // Additional properties
  map<string, string> properties = 4;
}

// Bounding box for UI elements
message ElementBounds {
  int32 x = 1;
  int32 y = 2;
  int32 width = 3;
  int32 height = 4;
}

// Response with available models
message ModelsResponse {
  repeated ModelInfo models = 1;
}

// Information about a vision model
message ModelInfo {
  string name = 1;
  string display_name = 2;
  string description = 3;
  bool available = 4;
  int64 memory_usage_mb = 5;
  repeated string supported_types = 6;
}

// Request for model metrics
message ModelMetricsRequest {
  string model = 1;
}

// Response with model performance metrics
message ModelMetricsResponse {
  string model = 1;
  int64 total_inferences = 2;
  double average_processing_time = 3;
  double average_confidence = 4;
  int64 memory_usage_mb = 5;
  double gpu_utilization = 6;
  map<string, double> additional_metrics = 7;
}

// Empty message for requests with no parameters
message Empty {}

// Health check response - using simplified version for now
message HealthResponse {
  bool healthy = 1;
  string status = 2;
  map<string, string> details = 3;
  int64 uptime_seconds = 4;
  string version = 5;
}
